{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Mat3ra API Examples","text":""},{"location":"#contents-of-this-repository","title":"Contents of this Repository","text":"<p>Below, we list the contents of this repository, in roughly the order that a user might want to go through it in order to learn how our API works.</p> Folder Notebook Description Examples/System Get Authentication Params Demonstrates how to programatically find your user ID and access token, which is to authenticate for many portions of the Mat3ra API. Examples/Workflow Get Workflows Walks through how to query the Mat3ra API to programatically search for workflows. In this example, we search for workflows that calculate the total energy of a material. Examples/Workflow Quantum Espresso Workflow and Job Create Quantum Espresso workflow starting from QE input file; create and submit job; after the job is finished, download output file, and finally perform postprocessing analysis. Examples/Material Get Materials by Formula Shows how queries can be made to search for materials stored on your account by their formula. In this example, we search for a system containing Si. Examples/Material Create Material Gives an overview of how materials can be generated in JSON format and uploaded to your user account. In this example, we create an FCC Si crystal and upload it. Examples/Material Import Materials from Materials Project Demonstrates how materials can be imported from Materials Project, if their Materials Project ID is known. In this example, we import monoclinic and hexagonal SiGe cells. Examples/Material Import Materials from Poscar Provides an example of how materials can be imported directly from Poscar files (a common chemical file format best-known for its use in VASP). In this example, we import the unit cell of SiGe. Examples/Material Interoperability between Mat3ra and Materials Project In this notebook, we showcase a major advantage of APIs: interoperability. We begin by performing a query using the Materials Project API for all systems containing Iron and Oxygen. We then filter our results (for demonstraiton purposes, we keep only the first 10 materials found). Finally, we upload our results to the Mat3ra platform, where further calculations could be performed to characterize these materials. Examples/Job Create and Submit Job Shows how to use the Mat3ra API to create jobs and run them on our cluster. In this example, we run a DFT calculation to get the total energy of an FCC Si unit cell using Quantum Espresso. Examples/Job Get File from Job Guides you through using the Mat3ra API to query for a list of files produced by a job, describes the metadata assigned to each file, and ends by demonstrating how to download any remote file generated by a job to the local disk. Examples/Job Run Simulations and Extract Properties Leads you through the process of copying a bank workflow to your account and using it to automatically calculate the properties of multiple materials. In this example, we determine the band gap of Si and Ge. Examples/Job ML - Train Model Predict Properties Walks you through automated dataset generation and the training/prediction of material properties using machine learning. In this example, we calculate the band gaps of Si and SiGe, and using various materials properties as descriptors, train a model to predict their band gaps. Finally, we use this trained model to predict the band gap of Ge."},{"location":"#setup","title":"Setup","text":"<p>NOTE: tested with Python version 3.8 and 3.10, please assert that the virtual environment is created with it. Use <code>pyenv</code> to manage Python versions.</p> <p>Follow the steps below in order to setup and view the Jupyter notebooks:</p> <ol> <li> <p>Install git-lfs [3] in order to get access to the source code and notebook files.</p> </li> <li> <p>Clone repository:</p> <pre><code>git clone https://github.com/Exabyte-io/api-examples.git\n</code></pre> <p>Or, if you have set up SSH keys</p> <pre><code>git clone git@github.com:Exabyte-io/api-examples.git\n</code></pre> <p>In case for some reason git-lfs was not installed at the time of cloning, the files can be pulled after installing git-lfs, through <code>git lfs pull</code>.</p> <p>Related to this, please be aware that as the <code>.ipynb</code> and <code>.poscar</code> files are stored on git-lfs, they are not part of the zip archive downloaded through GitHub's web interface.</p> </li> <li> <p>Install virtualenv using pip if not already present:</p> <pre><code>pip install virtualenv\n</code></pre> </li> <li> <p>Create virtual environment and install required packages:</p> <pre><code>cd api-examples\nvirtualenv .env\nsource .env/bin/activate\npip install -e .\"[localhost]\"\n</code></pre> </li> <li> <p>Run Jupyter and open a notebook in a browser. In order for the post-save hook feature to work properly, one must launch their Jupyter Notebook environment in the folder that contains the file <code>config.py</code>, which is the <code>examples</code> folder shown below:</p> <pre><code>cd examples\njupyter lab --config=config.py\n</code></pre> </li> </ol>"},{"location":"#usage","title":"Usage","text":"<p>In order to run or edit the examples:</p> <ol> <li> <p>Assert an existing Mat3ra.com account. Examples require an account to run. New users can register here to obtain one.</p> </li> <li> <p>Open settings and adjust it to provide the API authentication parameters. See the corresponding example to learn how to obtain the authentication parameters. It is also possible to generate an API token by logging in to Mat3ra platform, navigating to the Account Preferences, and clicking the 'Generate new token' button under API Tokens. More details can be found here.</p> </li> <li> <p>Open the desired example notebook, adjust it as necessary and run. One can speed up the notebooks execution after running the Get Authentication Params one by reusing the kernel from the first notebook.</p> </li> </ol> <p></p> <p>NOTE: The Materials Project API key should be obtained from https://legacy.materialsproject.org/open.</p>"},{"location":"#contribute","title":"Contribute","text":"<p>This is an open-source repository and we welcome contributions for other use cases. The original set of examples is only meant to demonstrate the capabilities and can be extended.</p> <p>We suggest forking this repository and introducing the adjustments there. The changes in the fork can further be considered for merging into this repository as it is commonly used on GitHub. This process is explained in more details elsewhere online [4].</p> <p>If you would like to add new examples or adjust existing ones, please consider the following:</p> <ol> <li> <p>Put examples into the corresponding directories by domain.</p> </li> <li> <p>Walk the readers through the examples by providing step-by-step explanation similar to this example.</p> </li> <li> <p>We use post-save hooks to automatically convert notebooks to python scripts. See config file for more information. In order to facilitate code review, we exclude notebook sources in the <code>other/</code> directory from version control and store them in Git LFS [3]. Please follow this convention.</p> </li> <li> <p>Apply code formatting by installing development requirements as follows:</p> <pre><code>pip install -e .\"[dev]\"\npre-commit install\npre-commit run --all-files\n</code></pre> <p>Check more details about <code>pre-commit</code> here.</p> </li> </ol>"},{"location":"#links","title":"Links","text":"<ol> <li>Mat3ra.com RESTful API, description in the online documentation: link</li> <li>Jupyter.org, official website: link</li> <li>Git Large File Storage, official website: link</li> <li>GitHub Standard Fork &amp; Pull Request Workflow, online explanation: link</li> </ol>"},{"location":"examples/assets/","title":"Assets for Notebooks","text":"<p>This directory contains various files for the example notebooks.</p> <ul> <li><code>mp-978534.poscar</code> contains a SiGe structure from https://materialsproject.org/materials/mp-978534/.</li> <li><code>bash_workflow_template.json</code> contains the template JSON schema of Mat3ra workflow.</li> <li><code>Si.pz-vbc.UPF</code> is the pseudo potential file of silicon used in the Quantum Espresso workflow example.</li> </ul>"},{"location":"examples/job/create_and_submit_job/","title":"Create and Submit Job","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[2]: Copied! <pre>from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID\nfrom utils.generic import display_JSON\n\nfrom exabyte_api_client.endpoints.jobs import JobEndpoints\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\nfrom exabyte_api_client.endpoints.workflows import WorkflowEndpoints\n</pre> from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID from utils.generic import display_JSON  from exabyte_api_client.endpoints.jobs import JobEndpoints from exabyte_api_client.endpoints.materials import MaterialEndpoints from exabyte_api_client.endpoints.workflows import WorkflowEndpoints In\u00a0[3]: Copied! <pre>job_endpoints = JobEndpoints(*ENDPOINT_ARGS)\nmaterial_endpoints = MaterialEndpoints(*ENDPOINT_ARGS)\nworkflow_endpoints = WorkflowEndpoints(*ENDPOINT_ARGS)\n</pre> job_endpoints = JobEndpoints(*ENDPOINT_ARGS) material_endpoints = MaterialEndpoints(*ENDPOINT_ARGS) workflow_endpoints = WorkflowEndpoints(*ENDPOINT_ARGS) <p>Set job name.</p> In\u00a0[4]: Copied! <pre>JOB_NAME = \"TEST JOB\"\n</pre> JOB_NAME = \"TEST JOB\" In\u00a0[5]: Copied! <pre>default_material = material_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0]\ndefault_workflow = workflow_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0]\n\nmaterial_id = default_material[\"_id\"]\nworkflow_id = default_workflow[\"_id\"]\nowner_id = default_material[\"owner\"][\"_id\"]\n</pre> default_material = material_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0] default_workflow = workflow_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0]  material_id = default_material[\"_id\"] workflow_id = default_workflow[\"_id\"] owner_id = default_material[\"owner\"][\"_id\"] In\u00a0[6]: Copied! <pre>config = {\n    \"owner\": {\"_id\": owner_id},\n    \"_material\": {\"_id\": material_id},\n    \"workflow\": {\"_id\": workflow_id},\n    \"name\": JOB_NAME,\n}\n</pre> config = {     \"owner\": {\"_id\": owner_id},     \"_material\": {\"_id\": material_id},     \"workflow\": {\"_id\": workflow_id},     \"name\": JOB_NAME, } In\u00a0[7]: Copied! <pre>job = job_endpoints.create(config)\njob_endpoints.submit(job[\"_id\"])\n</pre> job = job_endpoints.create(config) job_endpoints.submit(job[\"_id\"]) In\u00a0[8]: Copied! <pre>job = job_endpoints.get(job[\"_id\"])\ndisplay_JSON(job)\n</pre> job = job_endpoints.get(job[\"_id\"]) display_JSON(job)"},{"location":"examples/job/create_and_submit_job/#overview","title":"Overview\u00b6","text":"<p>This example demonstrates how to create and submit a job via Job endpoints.</p>"},{"location":"examples/job/create_and_submit_job/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/job/create_and_submit_job/#initialize-the-endpoints","title":"Initialize the endpoints\u00b6","text":""},{"location":"examples/job/create_and_submit_job/#retrieve-ids","title":"Retrieve IDs\u00b6","text":"<p>Default account's materail and workflow are used in this example to create the job. Adjust the queries to use different material and workflow.</p>"},{"location":"examples/job/create_and_submit_job/#create-job-config","title":"Create job config\u00b6","text":"<p>The job belongs to user's default account and it is created inside the defauult account's project.</p>"},{"location":"examples/job/create_and_submit_job/#create-and-submit-job","title":"Create and submit job\u00b6","text":""},{"location":"examples/job/create_and_submit_job/#print-the-job","title":"Print the job\u00b6","text":"<p>Print the job in pretty JSON below. Check <code>status</code> field to make sure job is submiited.</p>"},{"location":"examples/job/get-file-from-job/","title":"Get File from Job","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[2]: Copied! <pre># Import settings file and utils file\nfrom utils.settings import ENDPOINT_ARGS, ACCOUNT_ID, MATERIALS_PROJECT_API_KEY\nfrom utils.generic import (\n    wait_for_jobs_to_finish,\n    get_property_by_subworkflow_and_unit_indicies,\n    dataframe_to_html,\n    display_JSON,\n)\n\n# Relevant functions from the API client\nfrom exabyte_api_client.endpoints.jobs import JobEndpoints\nfrom exabyte_api_client.endpoints.projects import ProjectEndpoints\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\nfrom exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints\nfrom exabyte_api_client.endpoints.raw_properties import RawPropertiesEndpoints\n</pre> # Import settings file and utils file from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID, MATERIALS_PROJECT_API_KEY from utils.generic import (     wait_for_jobs_to_finish,     get_property_by_subworkflow_and_unit_indicies,     dataframe_to_html,     display_JSON, )  # Relevant functions from the API client from exabyte_api_client.endpoints.jobs import JobEndpoints from exabyte_api_client.endpoints.projects import ProjectEndpoints from exabyte_api_client.endpoints.materials import MaterialEndpoints from exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints from exabyte_api_client.endpoints.raw_properties import RawPropertiesEndpoints In\u00a0[3]: Copied! <pre># Get some account information\nproject_endpoints = ProjectEndpoints(*ENDPOINT_ARGS)\nproject_metadata = project_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0]\nproject_id = project_metadata[\"_id\"]\nowner_id = project_metadata[\"owner\"][\"_id\"]\n\n# Get a workflow for the job from the bank, and copy it to our account\nbank_workflow_endpoints = BankWorkflowEndpoints(*ENDPOINT_ARGS)\nBANK_WORKFLOW_ID = \"84DAjE9YyTFndx6z3\"\nworkflow_id = bank_workflow_endpoints.copy(BANK_WORKFLOW_ID, owner_id)[\"_id\"]\n\n# Get materials for the job\nmaterial_endpoints = MaterialEndpoints(*ENDPOINT_ARGS)\nmaterial_project_id = [\"mp-149\"]  # The importer expects a list\nmaterials = material_endpoints.import_from_materialsproject(MATERIALS_PROJECT_API_KEY, material_project_id, owner_id)\n\n# Create the job\njob_endpoints = JobEndpoints(*ENDPOINT_ARGS)\njob = job_endpoints.create_by_ids(\n    materials=materials, workflow_id=workflow_id, project_id=project_id, owner_id=owner_id, prefix=\"Test_Job_Output\"\n)[0]\n\n# Submit the job\njob_endpoints.submit(job[\"_id\"])\nwait_for_jobs_to_finish(job_endpoints, [job[\"_id\"]])\n</pre> # Get some account information project_endpoints = ProjectEndpoints(*ENDPOINT_ARGS) project_metadata = project_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0] project_id = project_metadata[\"_id\"] owner_id = project_metadata[\"owner\"][\"_id\"]  # Get a workflow for the job from the bank, and copy it to our account bank_workflow_endpoints = BankWorkflowEndpoints(*ENDPOINT_ARGS) BANK_WORKFLOW_ID = \"84DAjE9YyTFndx6z3\" workflow_id = bank_workflow_endpoints.copy(BANK_WORKFLOW_ID, owner_id)[\"_id\"]  # Get materials for the job material_endpoints = MaterialEndpoints(*ENDPOINT_ARGS) material_project_id = [\"mp-149\"]  # The importer expects a list materials = material_endpoints.import_from_materialsproject(MATERIALS_PROJECT_API_KEY, material_project_id, owner_id)  # Create the job job_endpoints = JobEndpoints(*ENDPOINT_ARGS) job = job_endpoints.create_by_ids(     materials=materials, workflow_id=workflow_id, project_id=project_id, owner_id=owner_id, prefix=\"Test_Job_Output\" )[0]  # Submit the job job_endpoints.submit(job[\"_id\"]) wait_for_jobs_to_finish(job_endpoints, [job[\"_id\"]]) <pre>Wait for jobs to finish, poll interval: 10 sec\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:18:16 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:18:26 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:18:37 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:18:47 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:18:57 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:19:08 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:19:18 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:19:29 |                0 |             1 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:19:39 |                0 |             1 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:19:50 |                0 |             1 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:20:00 |                0 |             0 |               1 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n</pre> <p>Monitor the jobs and print the status until they are all finished.</p> In\u00a0[4]: Copied! <pre>files = job_endpoints.list_files(job[\"_id\"])\npaths = [file[\"key\"] for file in files]\nfor path in paths:\n    if \"outdir\" not in path:\n        print(path)\n</pre> files = job_endpoints.list_files(job[\"_id\"]) paths = [file[\"key\"] for file in files] for path in paths:     if \"outdir\" not in path:         print(path) <pre>/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/.exabyte/92538.master-production-20160630-cluster-001.exabyte.io\n/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/.exabyte/checkpoint\n/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/.exabyte/job.rms\n/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/.exabyte/machines-92538.master-production-20160630-cluster-001.exabyte.io\n/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/.exabyte/rupy.log\n/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/F6DrciP3aTGyqd4Yk.json\n/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/job.log\n/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/pseudo/si_pbe_gbrv_1.0.upf\n/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/pw_scf.in\n/cluster-001-home/demo/data/demo/test-job-output-si-207-F6DrciP3aTGyqd4Yk/pw_scf.out\n</pre> In\u00a0[5]: Copied! <pre>for file in files:\n    if file[\"name\"] == \"pw_scf.out\":\n        output_file_metadata = file\ndisplay_JSON(output_file_metadata)\n</pre> for file in files:     if file[\"name\"] == \"pw_scf.out\":         output_file_metadata = file display_JSON(output_file_metadata) In\u00a0[6]: Copied! <pre>import urllib\n\nserver_response = urllib.request.urlopen(output_file_metadata[\"signedUrl\"])\noutput_file_bytes = server_response.read()\n\n# The server returns us a bytes-string. That's useful for things like binaries or other non-human-readable data, but this should be decoded if we're planning to write to console.\n# Because this is a human-readable text file, we'll decode it to UTF-8.\noutput_file = output_file_bytes.decode(encoding=\"UTF-8\")\n\n# Tail the last 90 lines\nlines = output_file.split(\"\\n\")\nfor line in lines[-90:]:\n    print(line)\n</pre> import urllib  server_response = urllib.request.urlopen(output_file_metadata[\"signedUrl\"]) output_file_bytes = server_response.read()  # The server returns us a bytes-string. That's useful for things like binaries or other non-human-readable data, but this should be decoded if we're planning to write to console. # Because this is a human-readable text file, we'll decode it to UTF-8. output_file = output_file_bytes.decode(encoding=\"UTF-8\")  # Tail the last 90 lines lines = output_file.split(\"\\n\") for line in lines[-90:]:     print(line) <pre>\n    -1.5106  -1.5106   3.4108   3.4108   6.9197   6.9197  16.1487  16.1487\n\n     the Fermi energy is     6.6081 ev\n\n!    total energy              =     -19.00890069 Ry\n     Harris-Foulkes estimate   =     -19.00890026 Ry\n     estimated scf accuracy    &lt;       0.00000057 Ry\n\n     The total energy is the sum of the following terms:\n\n     one-electron contribution =       5.04610005 Ry\n     hartree contribution      =       1.30263425 Ry\n     xc contribution           =      -8.67765820 Ry\n     ewald contribution        =     -16.67997678 Ry\n     smearing contrib. (-TS)   =      -0.00000000 Ry\n\n     convergence has been achieved in   6 iterations\n\n     Forces acting on atoms (Ry/au):\n\n     atom    1 type  1   force =    -0.00000037    0.00000042    0.00000000\n     atom    2 type  1   force =     0.00000037   -0.00000042    0.00000000\n\n     Total force =     0.000001     Total SCF correction =     0.000002\n     SCF correction compared to forces is large: reduce conv_thr to get better values\n\n\n     entering subroutine stress ...\n\n          total   stress  (Ry/bohr**3)                   (kbar)     P=   73.74\n   0.00050127   0.00000001   0.00000000         73.74      0.00      0.00\n   0.00000001   0.00050125  -0.00000000          0.00     73.74     -0.00\n   0.00000000  -0.00000000   0.00050127          0.00     -0.00     73.74\n\n\n     Writing output data file __prefix__.save\n \n     init_run     :      0.29s CPU      0.32s WALL (       1 calls)\n     electrons    :      1.56s CPU      1.84s WALL (       1 calls)\n     forces       :      0.09s CPU      0.11s WALL (       1 calls)\n     stress       :      0.31s CPU      0.35s WALL (       1 calls)\n\n     Called by init_run:\n     wfcinit      :      0.05s CPU      0.05s WALL (       1 calls)\n     potinit      :      0.03s CPU      0.04s WALL (       1 calls)\n\n     Called by electrons:\n     c_bands      :      0.87s CPU      0.88s WALL (       6 calls)\n     sum_band     :      0.39s CPU      0.51s WALL (       6 calls)\n     v_of_rho     :      0.16s CPU      0.17s WALL (       7 calls)\n     newd         :      0.17s CPU      0.32s WALL (       7 calls)\n     mix_rho      :      0.02s CPU      0.02s WALL (       6 calls)\n\n     Called by c_bands:\n     init_us_2    :      0.02s CPU      0.02s WALL (      90 calls)\n     cegterg      :      0.77s CPU      0.78s WALL (      36 calls)\n\n     Called by sum_band:\n     sum_band:bec :      0.00s CPU      0.00s WALL (      36 calls)\n     addusdens    :      0.21s CPU      0.33s WALL (       6 calls)\n\n     Called by *egterg:\n     h_psi        :      0.75s CPU      0.76s WALL (     127 calls)\n     s_psi        :      0.01s CPU      0.01s WALL (     127 calls)\n     g_psi        :      0.00s CPU      0.00s WALL (      85 calls)\n     cdiaghg      :      0.01s CPU      0.01s WALL (     121 calls)\n\n     Called by h_psi:\n     add_vuspsi   :      0.01s CPU      0.01s WALL (     127 calls)\n\n     General routines\n     calbec       :      0.02s CPU      0.02s WALL (     193 calls)\n     fft          :      0.13s CPU      0.13s WALL (     133 calls)\n     ffts         :      0.01s CPU      0.01s WALL (      13 calls)\n     fftw         :      0.78s CPU      0.79s WALL (    1912 calls)\n     interpolate  :      0.02s CPU      0.02s WALL (      13 calls)\n \n     Parallel routines\n     fft_scatter  :      0.05s CPU      0.05s WALL (    2058 calls)\n \n     PWSCF        :     2.30s CPU         3.19s WALL\n\n \n   This run was terminated on:  15:19:31  28Jul2023            \n\n=------------------------------------------------------------------------------=\n   JOB DONE.\n=------------------------------------------------------------------------------=\n\n</pre> In\u00a0[7]: Copied! <pre># We've already got an output file, so let's grab the input file we sent to Quantum Espresso\nfor file in files:\n    if \"pw_scf.in\" == file[\"name\"]:\n        input_file_metadata = file\nserver_response = urllib.request.urlopen(input_file_metadata[\"signedUrl\"])\ninput_file_bytes = server_response.read()\n</pre> # We've already got an output file, so let's grab the input file we sent to Quantum Espresso for file in files:     if \"pw_scf.in\" == file[\"name\"]:         input_file_metadata = file server_response = urllib.request.urlopen(input_file_metadata[\"signedUrl\"]) input_file_bytes = server_response.read() In\u00a0[8]: Copied! <pre># Let's write the input file to disk. Note that we get files as a bytes string from the server, which is convenient for binaries, images, and other non-human-readable data.\n# Although we could decode before writing to disk, we can just write it directly with the \"wb\" (write bytes) file mode.\nwith open(input_file_metadata[\"name\"], \"wb\") as file_descriptor:\n    file_descriptor.write(input_file_bytes)\n</pre> # Let's write the input file to disk. Note that we get files as a bytes string from the server, which is convenient for binaries, images, and other non-human-readable data. # Although we could decode before writing to disk, we can just write it directly with the \"wb\" (write bytes) file mode. with open(input_file_metadata[\"name\"], \"wb\") as file_descriptor:     file_descriptor.write(input_file_bytes) In\u00a0[9]: Copied! <pre># Now, let's write our output file to the disk. Note that because we already decoded it, we can just use the 'w' file mode.\nwith open(output_file_metadata[\"name\"], \"w\") as file_descriptor:\n    file_descriptor.write(output_file)\n</pre> # Now, let's write our output file to the disk. Note that because we already decoded it, we can just use the 'w' file mode. with open(output_file_metadata[\"name\"], \"w\") as file_descriptor:     file_descriptor.write(output_file)"},{"location":"examples/job/get-file-from-job/#get-file-from-job","title":"Get-File-From-Job\u00b6","text":"<p>This example demonstrates how to use Mat3ra RESTful API to check for and acquire files from jobs which have been run. This example assumes that the user is already familiar with the creation and submission of jobs using our API.</p> <p>IMPORTANT NOTE: In order to run this example in full, an active Mat3ra.com account is required. Alternatively, Readers may substitute the workflow ID below with another one (an equivalent one for VASP, for example) and adjust extraction of the results (\"Viewing job files\" section). RESTful API credentials shall be updated in settings.</p>"},{"location":"examples/job/get-file-from-job/#steps","title":"Steps\u00b6","text":"<p>After working through this notebook, you will be able to:</p> <ol> <li>Import the structure of Si from Materials Project</li> <li>Set up and run a single-point calculation using Quantum Espresso.</li> <li>List files currently in the job's directory</li> <li>Check metadata for every file (modification date, size, etc)</li> <li>Access file contents directly and print them to console</li> <li>Download files to your local machine</li> </ol>"},{"location":"examples/job/get-file-from-job/#pre-requisites","title":"Pre-requisites\u00b6","text":"<p>The explanation below assumes that the reader is familiar with the concepts used in Mat3ra platform and RESTful API. We outline these below and direct the reader to the original sources of information:</p> <ul> <li>Generating RESTful API authentication parameters</li> <li>Importing materials from materials project</li> <li>Creating and submitting jobs</li> </ul>"},{"location":"examples/job/get-file-from-job/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/job/get-file-from-job/#imports","title":"Imports\u00b6","text":""},{"location":"examples/job/get-file-from-job/#create-and-submit-the-job","title":"Create and submit the job\u00b6","text":"<p>For this job, we'll use the workflow located here.</p> <p>This workflow is a single-point total energy calculation using Density-Functional Energy as-implemented in Quantum Espresso version 5.4.0.</p> <p>The PBE functional is used in conjunction with an ultrasoft pseudopotential and a planewave basis set.</p> <p>The material we will investigate is elemental Silicon, as-is from Materials Project.</p> <p>Note: This cell uses our API to copy the unit cell of silicon from Materials Project into your account. It then copies a workflow to get the total energy of a system using Quantum Espresso to your account. Finally, a job is created using the Quantum Espresso workflow for the silicon unit cell, and the job is submitted to the cluster. For more information, please refer to our run-simulation-and-extract-properties notebook, located in this directory.</p>"},{"location":"examples/job/get-file-from-job/#viewing-job-files","title":"Viewing job files\u00b6","text":""},{"location":"examples/job/get-file-from-job/#retreive-a-list-of-job-files","title":"Retreive a list of job files\u00b6","text":"<p>Here, we'll get a list of all files that belong to the job.</p>"},{"location":"examples/job/get-file-from-job/#get-metadata-for-the-output-file","title":"Get metadata for the Output File\u00b6","text":"<p>The .out file is where Quantum Espresso shows its work and prints its results, so you most likely will want to view this files. Let's print out some of its metadata.</p> <p>You'll find that we get a lot of data describing the file and its providence. Brief explanations of each entry are:</p> <ul> <li>Key - Path to the file on the cluster</li> <li>size - Size of the file, in bytes.</li> <li>Bucket - The name of the cluster which ran the job.</li> <li>Region - Which server region was used to run the job.</li> <li>Provider - The cluster provider for the compute resources (in our case, we used AWS).</li> <li>lastModified - Unix timestamp representing when the file was last modified.</li> <li>name - The filename.</li> <li>signedUrl - This is a link which can be used to download the file for a short amount of time.</li> </ul>"},{"location":"examples/job/get-file-from-job/#display-file-contents-to-console","title":"Display file contents to console\u00b6","text":"<p>The signedUrl gives us a place to access the file and download it. Let's read it into memory, and print out the last few lines of our job.</p>"},{"location":"examples/job/get-file-from-job/#save-the-input-file-and-output-file-to-disk","title":"Save the input file and output file to disk.\u00b6","text":"<p>Now that we've verified the job is done, let's go ahead and save it and its input to disk.</p>"},{"location":"examples/job/ml-train-model-predict-properties/","title":"ML - Train Model Predict Properties","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[2]: Copied! <pre>import time\nfrom IPython.display import IFrame\n\n# Import settings file and utils file\nfrom utils.settings import ENDPOINT_ARGS, ACCOUNT_ID, MATERIALS_PROJECT_API_KEY\nfrom utils.generic import (\n    dataframe_to_html,\n    copy_bank_workflow_by_system_name,\n    wait_for_jobs_to_finish,\n    get_property_by_subworkflow_and_unit_indicies,\n    display_JSON,\n)\n\nimport pandas as pd\n\n# Import relevant portions of the API client\nfrom exabyte_api_client.endpoints.jobs import JobEndpoints\nfrom exabyte_api_client.utils.materials import flatten_material\nfrom exabyte_api_client.endpoints.projects import ProjectEndpoints\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\nfrom exabyte_api_client.endpoints.workflows import WorkflowEndpoints\nfrom exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints\nfrom exabyte_api_client.endpoints.raw_properties import RawPropertiesEndpoints\n</pre> import time from IPython.display import IFrame  # Import settings file and utils file from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID, MATERIALS_PROJECT_API_KEY from utils.generic import (     dataframe_to_html,     copy_bank_workflow_by_system_name,     wait_for_jobs_to_finish,     get_property_by_subworkflow_and_unit_indicies,     display_JSON, )  import pandas as pd  # Import relevant portions of the API client from exabyte_api_client.endpoints.jobs import JobEndpoints from exabyte_api_client.utils.materials import flatten_material from exabyte_api_client.endpoints.projects import ProjectEndpoints from exabyte_api_client.endpoints.materials import MaterialEndpoints from exabyte_api_client.endpoints.workflows import WorkflowEndpoints from exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints from exabyte_api_client.endpoints.raw_properties import RawPropertiesEndpoints In\u00a0[3]: Copied! <pre>TRAIN_MATERIALS_PROJECT_IDS = [\"mp-149\", \"mp-978534\"]  # Si, SiGe\nTARGET_MATERIALS_PROJECT_IDS = [\"mp-32\"]  # Ge\n</pre> TRAIN_MATERIALS_PROJECT_IDS = [\"mp-149\", \"mp-978534\"]  # Si, SiGe TARGET_MATERIALS_PROJECT_IDS = [\"mp-32\"]  # Ge In\u00a0[4]: Copied! <pre>JOB_NAME_PREFIX = \"Job Name Prefix\"\n</pre> JOB_NAME_PREFIX = \"Job Name Prefix\" In\u00a0[5]: Copied! <pre>PPN = \"1\"\nQUEUE = \"D\"\nNODES = \"1\"\nTIME_LIMIT = \"01:00:00\"\nCLUSTER = \"cluster-001\"\n</pre> PPN = \"1\" QUEUE = \"D\" NODES = \"1\" TIME_LIMIT = \"01:00:00\" CLUSTER = \"cluster-001\" In\u00a0[6]: Copied! <pre>job_endpoints = JobEndpoints(*ENDPOINT_ARGS)\nproject_endpoints = ProjectEndpoints(*ENDPOINT_ARGS)\nmaterial_endpoints = MaterialEndpoints(*ENDPOINT_ARGS)\nworkflow_endpoints = WorkflowEndpoints(*ENDPOINT_ARGS)\nbank_workflow_endpoints = BankWorkflowEndpoints(*ENDPOINT_ARGS)\nraw_property_endpoints = RawPropertiesEndpoints(*ENDPOINT_ARGS)\n</pre> job_endpoints = JobEndpoints(*ENDPOINT_ARGS) project_endpoints = ProjectEndpoints(*ENDPOINT_ARGS) material_endpoints = MaterialEndpoints(*ENDPOINT_ARGS) workflow_endpoints = WorkflowEndpoints(*ENDPOINT_ARGS) bank_workflow_endpoints = BankWorkflowEndpoints(*ENDPOINT_ARGS) raw_property_endpoints = RawPropertiesEndpoints(*ENDPOINT_ARGS) <p>Retrieve the owner and project IDs as they are needed by the endpoints. The default material is used to extract the owner ID. One can extract the owner ID from any other account's entities.</p> In\u00a0[7]: Copied! <pre>owner_id = material_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0][\"owner\"][\"_id\"]\nproject_id = project_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0][\"_id\"]\n</pre> owner_id = material_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0][\"owner\"][\"_id\"] project_id = project_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0][\"_id\"] In\u00a0[8]: Copied! <pre>band_gap_workflow_id = copy_bank_workflow_by_system_name(bank_workflow_endpoints, \"espresso-band-gap\", owner_id)\nml_train_workflow_id = copy_bank_workflow_by_system_name(bank_workflow_endpoints, \"exabyteml-ml-train-model\", owner_id)\n</pre> band_gap_workflow_id = copy_bank_workflow_by_system_name(bank_workflow_endpoints, \"espresso-band-gap\", owner_id) ml_train_workflow_id = copy_bank_workflow_by_system_name(bank_workflow_endpoints, \"exabyteml-ml-train-model\", owner_id) In\u00a0[9]: Copied! <pre>train_materials = material_endpoints.import_from_materialsproject(\n    MATERIALS_PROJECT_API_KEY, TRAIN_MATERIALS_PROJECT_IDS, owner_id\n)\ntarget_materials = material_endpoints.import_from_materialsproject(\n    MATERIALS_PROJECT_API_KEY, TARGET_MATERIALS_PROJECT_IDS, owner_id\n)\n</pre> train_materials = material_endpoints.import_from_materialsproject(     MATERIALS_PROJECT_API_KEY, TRAIN_MATERIALS_PROJECT_IDS, owner_id ) target_materials = material_endpoints.import_from_materialsproject(     MATERIALS_PROJECT_API_KEY, TARGET_MATERIALS_PROJECT_IDS, owner_id ) In\u00a0[10]: Copied! <pre>compute = job_endpoints.get_compute(CLUSTER, PPN, NODES, QUEUE, TIME_LIMIT)\njobs = job_endpoints.create_by_ids(\n    train_materials, band_gap_workflow_id, project_id, owner_id, JOB_NAME_PREFIX, compute\n)\n</pre> compute = job_endpoints.get_compute(CLUSTER, PPN, NODES, QUEUE, TIME_LIMIT) jobs = job_endpoints.create_by_ids(     train_materials, band_gap_workflow_id, project_id, owner_id, JOB_NAME_PREFIX, compute ) <p>Submit the jobs for execution.</p> In\u00a0[11]: Copied! <pre>for job in jobs:\n    job_endpoints.submit(job[\"_id\"])\n</pre> for job in jobs:     job_endpoints.submit(job[\"_id\"]) <p>Monitor the jobs and print the status until they are all finished.</p> In\u00a0[12]: Copied! <pre>job_ids = [job[\"_id\"] for job in jobs]\nwait_for_jobs_to_finish(job_endpoints, job_ids)\n</pre> job_ids = [job[\"_id\"] for job in jobs] wait_for_jobs_to_finish(job_endpoints, job_ids) <pre>Wait for jobs to finish, poll interval: 10 sec\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:20:23 |                2 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:20:34 |                2 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:20:44 |                2 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:20:55 |                2 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:21:05 |                0 |             2 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:21:16 |                0 |             2 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:21:26 |                0 |             2 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:21:36 |                0 |             2 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:21:47 |                0 |             1 |               1 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:21:57 |                0 |             1 |               1 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:22:08 |                0 |             0 |               2 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n</pre> In\u00a0[13]: Copied! <pre>name = \"-\".join((JOB_NAME_PREFIX, \"train\"))\nmaterial_ids = [m[\"_id\"] for m in train_materials]\nconfig = job_endpoints.get_config(material_ids, ml_train_workflow_id, project_id, owner_id, name, compute, True)\njob = job_endpoints.create(config)\n</pre> name = \"-\".join((JOB_NAME_PREFIX, \"train\")) material_ids = [m[\"_id\"] for m in train_materials] config = job_endpoints.get_config(material_ids, ml_train_workflow_id, project_id, owner_id, name, compute, True) job = job_endpoints.create(config) <p>Submit the train job for execution.</p> In\u00a0[14]: Copied! <pre>job_endpoints.submit(job[\"_id\"])\n</pre> job_endpoints.submit(job[\"_id\"]) <p>Monitor the job and print the status until it is done.</p> In\u00a0[15]: Copied! <pre>wait_for_jobs_to_finish(job_endpoints, [job[\"_id\"]])\n</pre> wait_for_jobs_to_finish(job_endpoints, [job[\"_id\"]]) <pre>Wait for jobs to finish, poll interval: 10 sec\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:22:09 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:22:20 |                0 |             1 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:22:30 |                0 |             1 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:22:41 |                0 |             1 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:22:51 |                0 |             0 |               1 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n</pre> In\u00a0[16]: Copied! <pre>ml_predict_workflow = get_property_by_subworkflow_and_unit_indicies(\n    raw_property_endpoints, \"workflow:ml_predict\", job, 0, 4\n)[\"data\"]\nml_predict_workflow_id = ml_predict_workflow[\"_id\"]\n</pre> ml_predict_workflow = get_property_by_subworkflow_and_unit_indicies(     raw_property_endpoints, \"workflow:ml_predict\", job, 0, 4 )[\"data\"] ml_predict_workflow_id = ml_predict_workflow[\"_id\"] <p>Print ML predict workflow</p> In\u00a0[17]: Copied! <pre>display_JSON(ml_predict_workflow)\n</pre> display_JSON(ml_predict_workflow) In\u00a0[18]: Copied! <pre>name = \"-\".join((JOB_NAME_PREFIX, \"predict\"))\nmaterial_ids = [m[\"_id\"] for m in target_materials]\nconfig = job_endpoints.get_config(material_ids, ml_predict_workflow_id, project_id, owner_id, name, compute, True)\njob = job_endpoints.create(config)\n</pre> name = \"-\".join((JOB_NAME_PREFIX, \"predict\")) material_ids = [m[\"_id\"] for m in target_materials] config = job_endpoints.get_config(material_ids, ml_predict_workflow_id, project_id, owner_id, name, compute, True) job = job_endpoints.create(config) <p>Submit the predict job for execution.</p> In\u00a0[19]: Copied! <pre>job_endpoints.submit(job[\"_id\"])\n</pre> job_endpoints.submit(job[\"_id\"]) <p>Monitor the job and print the status until its done.</p> In\u00a0[20]: Copied! <pre>wait_for_jobs_to_finish(job_endpoints, [job[\"_id\"]])\n</pre> wait_for_jobs_to_finish(job_endpoints, [job[\"_id\"]]) <pre>Wait for jobs to finish, poll interval: 10 sec\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:22:53 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:23:03 |                0 |             1 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:23:14 |                0 |             0 |               1 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n</pre> In\u00a0[21]: Copied! <pre>predicted_properties = get_property_by_subworkflow_and_unit_indicies(\n    raw_property_endpoints, \"predicted_properties\", job, 0, 3\n)[\"data\"][\"values\"]\n</pre> predicted_properties = get_property_by_subworkflow_and_unit_indicies(     raw_property_endpoints, \"predicted_properties\", job, 0, 3 )[\"data\"][\"values\"] In\u00a0[22]: Copied! <pre>table = []\nfor exabyte_id, properties in predicted_properties.items():\n    material = next((m for m in target_materials if m[\"exabyteId\"] == exabyte_id))\n    band_gaps = next((v for v in properties if v[\"name\"] == \"band_gaps\"))\n    direct_gap = next((v for v in band_gaps[\"values\"] if v[\"type\"] == \"direct\"))[\"value\"]\n    indirect_gap = next((v for v in band_gaps[\"values\"] if v[\"type\"] == \"indirect\"))[\"value\"]\n    table.append(\n        [material[\"_id\"], material[\"name\"], material[\"formula\"], material[\"exabyteId\"], direct_gap, indirect_gap]\n    )\n</pre> table = [] for exabyte_id, properties in predicted_properties.items():     material = next((m for m in target_materials if m[\"exabyteId\"] == exabyte_id))     band_gaps = next((v for v in properties if v[\"name\"] == \"band_gaps\"))     direct_gap = next((v for v in band_gaps[\"values\"] if v[\"type\"] == \"direct\"))[\"value\"]     indirect_gap = next((v for v in band_gaps[\"values\"] if v[\"type\"] == \"indirect\"))[\"value\"]     table.append(         [material[\"_id\"], material[\"name\"], material[\"formula\"], material[\"exabyteId\"], direct_gap, indirect_gap]     ) In\u00a0[23]: Copied! <pre>headers = [\"ID\", \"NAME\", \"FORMULA\", \"EXABYTE-ID\", \"DIRECT-GAP\", \"INDIRECT-GAP\"]\ndf = pd.DataFrame(data=table, columns=headers)\nhtml = dataframe_to_html(df)\nhtml\n</pre> headers = [\"ID\", \"NAME\", \"FORMULA\", \"EXABYTE-ID\", \"DIRECT-GAP\", \"INDIRECT-GAP\"] df = pd.DataFrame(data=table, columns=headers) html = dataframe_to_html(df) html Out[23]: ID NAME FORMULA EXABYTE-ID DIRECT-GAP INDIRECT-GAP 0 myocweCq5L9fWdRDh mp-32 Ge ts2ghFDZLBrKPiQaN 1.070000 0.465000"},{"location":"examples/job/ml-train-model-predict-properties/#overview","title":"Overview\u00b6","text":"<p>This example demonstrates how to use Mat3ra RESTful API to build a machine learning (ML) model for a set of materials called \"train materials\" and use the model to predict properties of another set called \"target materials\". The general approach can work for multiple properties, we use the Electronic Band Gap in this example.</p>"},{"location":"examples/job/ml-train-model-predict-properties/#steps","title":"Steps\u00b6","text":"<p>We follow the below steps:</p> <ul> <li>Import materials from materials project</li> <li>Calculate band gap for the \"train materials\"</li> <li>Build ML Train model based on the \"train materials\"</li> <li>Create and submit a job to predict band gap for the \"target materials\"</li> <li>Extract band gap for \"target materials\"</li> <li>Output the results as Pandas dataFrame</li> </ul>"},{"location":"examples/job/ml-train-model-predict-properties/#pre-requisites","title":"Pre-requisites\u00b6","text":"<p>The explanation below assumes that the reader is familiar with the concepts used in Mat3ra platform and RESTful API. We outline these below and direct the reader to the original sources of information:</p> <ul> <li>Generating RESTful API authentication parameters</li> <li>Importing materials from materials project</li> <li>Creating and submitting jobs</li> <li>Running DFT calculations</li> </ul>"},{"location":"examples/job/ml-train-model-predict-properties/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/job/ml-train-model-predict-properties/#imports","title":"Imports\u00b6","text":""},{"location":"examples/job/ml-train-model-predict-properties/#materials","title":"Materials\u00b6","text":"<p>Set parameters for the materials to be imported:</p> <ul> <li>TRAIN_MATERIALS_PROJECT_IDS: a list of material IDs to train ML model based on</li> <li>TARGET_MATERIALS_PROJECT_IDS: a list of material IDs to predict the property for</li> </ul>"},{"location":"examples/job/ml-train-model-predict-properties/#jobs","title":"Jobs\u00b6","text":"<p>Set parameters for the jobs to be ran for the imported materials:</p> <ul> <li>JOB_NAME_PREFIX: prefix to be used for the job name with \"{JOB_NAME_PREFIX} {FORMULA}\" convention (e.g.  \"Job Name Prefix - SiGe\")</li> </ul>"},{"location":"examples/job/ml-train-model-predict-properties/#compute","title":"Compute\u00b6","text":"<p>Setup compute parameters. See this for more information about compute parameters.</p> <ul> <li>NODES: Number of nodes. Defaults to 1.</li> <li>PPN: Number of MPI processes per each node, Defaults to 1.</li> <li>QUEUE: The name of queue to submit the jobs into. Defaults to D.</li> <li>TIME_LIMIT: Job walltime. Defaults to \"01:00:00\" (one hour).</li> <li>CLUSTER: The full qualified domain name (FQDN) or alias of the cluster to submit the jobs into.</li> </ul>"},{"location":"examples/job/ml-train-model-predict-properties/#initialize-the-endpoints","title":"Initialize the endpoints\u00b6","text":""},{"location":"examples/job/ml-train-model-predict-properties/#create-workflows","title":"Create workflows\u00b6","text":"<p>Copy \"ML: Train Model\" and \"Band Gap\" bank workflows to the account's workflows. We use exabyte bank workflows which are identified by \"systemName\" field. The below can be adjusted to get the bank workflows by ID.</p>"},{"location":"examples/job/ml-train-model-predict-properties/#import-materials","title":"Import materials\u00b6","text":"<p>Import materials from materials project.</p>"},{"location":"examples/job/ml-train-model-predict-properties/#calculate-properties-for-train-materials","title":"Calculate Properties for \"train materials\"\u00b6","text":"<p>Create jobs for the \"train materials\".</p>"},{"location":"examples/job/ml-train-model-predict-properties/#build-ml-train-model","title":"Build ML Train model\u00b6","text":"<p>Create ML Train job for the train materials.</p>"},{"location":"examples/job/ml-train-model-predict-properties/#extract-ml-model-as-workflow","title":"Extract ML model as workflow\u00b6","text":"<p>The resulting trained model is extracted from the last unit (train with index 4) of the first job's subworkflow (ML: Train Model with index 0) and is further referred to as \"ML predict workflow\".</p>"},{"location":"examples/job/ml-train-model-predict-properties/#predict-property-using-the-model","title":"Predict property using the model\u00b6","text":"<p>Create ML Predict job for the predict materials.</p>"},{"location":"examples/job/ml-train-model-predict-properties/#extract-predicted-properties","title":"Extract predicted properties\u00b6","text":"<p>Predicted properties are extracted from the last unit (score with index 3) of the first job's subworkflow (ml_predict_subworkflow with index 0).</p>"},{"location":"examples/job/ml-train-model-predict-properties/#flatten-results","title":"Flatten results\u00b6","text":"<p>The below for-loop iterates over the results and flatten them to form the final Pandas dataFrame.</p>"},{"location":"examples/job/ml-train-model-predict-properties/#ouput-results","title":"Ouput results\u00b6","text":"<p>Create and print the final table as Pandas dataFrame.</p>"},{"location":"examples/job/run-simulations-and-extract-properties/","title":"Run Simulations and Extract Properties","text":"In\u00a0[\u00a0]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[\u00a0]: Copied! <pre>import time\nfrom IPython.display import IFrame\n\n# Import settings file and utils file\nfrom utils.settings import ENDPOINT_ARGS, ACCOUNT_ID, MATERIALS_PROJECT_API_KEY\nfrom utils.generic import wait_for_jobs_to_finish, get_property_by_subworkflow_and_unit_indicies, dataframe_to_html\n\nimport pandas as pd\n\n# Relevant functions from the API client\nfrom exabyte_api_client.endpoints.jobs import JobEndpoints\nfrom exabyte_api_client.utils.materials import flatten_material\nfrom exabyte_api_client.endpoints.projects import ProjectEndpoints\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\nfrom exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints\nfrom exabyte_api_client.endpoints.raw_properties import RawPropertiesEndpoints\n</pre> import time from IPython.display import IFrame  # Import settings file and utils file from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID, MATERIALS_PROJECT_API_KEY from utils.generic import wait_for_jobs_to_finish, get_property_by_subworkflow_and_unit_indicies, dataframe_to_html  import pandas as pd  # Relevant functions from the API client from exabyte_api_client.endpoints.jobs import JobEndpoints from exabyte_api_client.utils.materials import flatten_material from exabyte_api_client.endpoints.projects import ProjectEndpoints from exabyte_api_client.endpoints.materials import MaterialEndpoints from exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints from exabyte_api_client.endpoints.raw_properties import RawPropertiesEndpoints In\u00a0[\u00a0]: Copied! <pre>MATERIALS_PROJECT_IDS = [\"mp-149\", \"mp-32\"]  # Si and Ge\nMATERIALS_SET_NAME = \"materials-set\"\nTAGS = [\"tag1\", \"tag2\"]\n</pre> MATERIALS_PROJECT_IDS = [\"mp-149\", \"mp-32\"]  # Si and Ge MATERIALS_SET_NAME = \"materials-set\" TAGS = [\"tag1\", \"tag2\"] In\u00a0[\u00a0]: Copied! <pre>JOB_NAME_PREFIX = \"Job Name Prefix\"\nJOBS_SET_NAME = \"jobs-set\"\n</pre> JOB_NAME_PREFIX = \"Job Name Prefix\" JOBS_SET_NAME = \"jobs-set\" In\u00a0[\u00a0]: Copied! <pre>BANK_WORKFLOW_ID = \"tPiF5dBQrY8pnik8r\"\n</pre> BANK_WORKFLOW_ID = \"tPiF5dBQrY8pnik8r\" In\u00a0[\u00a0]: Copied! <pre># Visualize the bank workflow below\n# NOTE: might not be rendered on Github\nIFrame(\"https://platform.mat3ra.com/analytics/workflows/{}\".format(BANK_WORKFLOW_ID), width=900, height=650)\n</pre> # Visualize the bank workflow below # NOTE: might not be rendered on Github IFrame(\"https://platform.mat3ra.com/analytics/workflows/{}\".format(BANK_WORKFLOW_ID), width=900, height=650) In\u00a0[\u00a0]: Copied! <pre>PPN = \"1\"\nQUEUE = \"D\"\nNODES = \"1\"\nTIME_LIMIT = \"01:00:00\"\nCLUSTER = \"cluster-001\"\n</pre> PPN = \"1\" QUEUE = \"D\" NODES = \"1\" TIME_LIMIT = \"01:00:00\" CLUSTER = \"cluster-001\" In\u00a0[\u00a0]: Copied! <pre>job_endpoints = JobEndpoints(*ENDPOINT_ARGS)\nproject_endpoints = ProjectEndpoints(*ENDPOINT_ARGS)\nmaterial_endpoints = MaterialEndpoints(*ENDPOINT_ARGS)\nraw_property_endpoints = RawPropertiesEndpoints(*ENDPOINT_ARGS)\nbank_workflow_endpoints = BankWorkflowEndpoints(*ENDPOINT_ARGS)\n</pre> job_endpoints = JobEndpoints(*ENDPOINT_ARGS) project_endpoints = ProjectEndpoints(*ENDPOINT_ARGS) material_endpoints = MaterialEndpoints(*ENDPOINT_ARGS) raw_property_endpoints = RawPropertiesEndpoints(*ENDPOINT_ARGS) bank_workflow_endpoints = BankWorkflowEndpoints(*ENDPOINT_ARGS) <p>Next, we retrieve the owner and project IDs as they are needed by the endpoints. Account's default material is used to extract the owner ID. One can extract the owner ID from any other account's entities.</p> In\u00a0[\u00a0]: Copied! <pre>owner_id = material_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0][\"owner\"][\"_id\"]\nproject_id = project_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0][\"_id\"]\n</pre> owner_id = material_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0][\"owner\"][\"_id\"] project_id = project_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0][\"_id\"] In\u00a0[\u00a0]: Copied! <pre>workflow_id = bank_workflow_endpoints.copy(BANK_WORKFLOW_ID, owner_id)[\"_id\"]\n</pre> workflow_id = bank_workflow_endpoints.copy(BANK_WORKFLOW_ID, owner_id)[\"_id\"] In\u00a0[\u00a0]: Copied! <pre>materials = material_endpoints.import_from_materialsproject(\n    MATERIALS_PROJECT_API_KEY, MATERIALS_PROJECT_IDS, owner_id, TAGS\n)\n</pre> materials = material_endpoints.import_from_materialsproject(     MATERIALS_PROJECT_API_KEY, MATERIALS_PROJECT_IDS, owner_id, TAGS ) <p>Create a materials set and move the materials into it.</p> In\u00a0[\u00a0]: Copied! <pre>materials_set = material_endpoints.create_set({\"name\": MATERIALS_SET_NAME, \"owner\": {\"_id\": owner_id}})\nfor material in materials:\n    material_endpoints.move_to_set(material[\"_id\"], \"\", materials_set[\"_id\"])\n</pre> materials_set = material_endpoints.create_set({\"name\": MATERIALS_SET_NAME, \"owner\": {\"_id\": owner_id}}) for material in materials:     material_endpoints.move_to_set(material[\"_id\"], \"\", materials_set[\"_id\"]) In\u00a0[\u00a0]: Copied! <pre>compute = job_endpoints.get_compute(CLUSTER, PPN, NODES, QUEUE, TIME_LIMIT)\njobs = job_endpoints.create_by_ids(materials, workflow_id, project_id, owner_id, JOB_NAME_PREFIX, compute)\n</pre> compute = job_endpoints.get_compute(CLUSTER, PPN, NODES, QUEUE, TIME_LIMIT) jobs = job_endpoints.create_by_ids(materials, workflow_id, project_id, owner_id, JOB_NAME_PREFIX, compute) <p>Create a jobs set and move the jobs into it.</p> In\u00a0[\u00a0]: Copied! <pre>jobs_set = job_endpoints.create_set({\"name\": JOBS_SET_NAME, \"projectId\": project_id, \"owner\": {\"_id\": owner_id}})\nfor job in jobs:\n    job_endpoints.move_to_set(job[\"_id\"], \"\", jobs_set[\"_id\"])\n</pre> jobs_set = job_endpoints.create_set({\"name\": JOBS_SET_NAME, \"projectId\": project_id, \"owner\": {\"_id\": owner_id}}) for job in jobs:     job_endpoints.move_to_set(job[\"_id\"], \"\", jobs_set[\"_id\"]) <p>Submit the jobs for execution.</p> In\u00a0[\u00a0]: Copied! <pre>for job in jobs:\n    job_endpoints.submit(job[\"_id\"])\n</pre> for job in jobs:     job_endpoints.submit(job[\"_id\"]) <p>Monitor the jobs and print the status until they are all finished.</p> In\u00a0[\u00a0]: Copied! <pre>job_ids = [job[\"_id\"] for job in jobs]\nwait_for_jobs_to_finish(job_endpoints, job_ids)\n</pre> job_ids = [job[\"_id\"] for job in jobs] wait_for_jobs_to_finish(job_endpoints, job_ids) In\u00a0[\u00a0]: Copied! <pre>results = []\nfor material in materials:\n    job = next((job for job in jobs if job[\"_material\"][\"_id\"] == material[\"_id\"]))\n    final_structure = get_property_by_subworkflow_and_unit_indicies(\n        raw_property_endpoints, \"final_structure\", job, 0, 0\n    )[\"data\"]\n    pressure = get_property_by_subworkflow_and_unit_indicies(raw_property_endpoints, \"pressure\", job, 0, 0)[\"data\"][\n        \"value\"\n    ]\n    unit_flowchart_id = job[\"workflow\"][\"subworkflows\"][1][\"units\"][1][\"flowchartId\"]\n    band_gap_direct = raw_property_endpoints.get_direct_band_gap(job[\"_id\"], unit_flowchart_id)\n    band_gap_indirect = raw_property_endpoints.get_indirect_band_gap(job[\"_id\"], unit_flowchart_id)\n    results.append(\n        {\n            \"initial_structure\": material,\n            \"final_structure\": final_structure,\n            \"pressure\": pressure,\n            \"band_gap_direct\": band_gap_direct,\n            \"band_gap_indirect\": band_gap_indirect,\n        }\n    )\n</pre> results = [] for material in materials:     job = next((job for job in jobs if job[\"_material\"][\"_id\"] == material[\"_id\"]))     final_structure = get_property_by_subworkflow_and_unit_indicies(         raw_property_endpoints, \"final_structure\", job, 0, 0     )[\"data\"]     pressure = get_property_by_subworkflow_and_unit_indicies(raw_property_endpoints, \"pressure\", job, 0, 0)[\"data\"][         \"value\"     ]     unit_flowchart_id = job[\"workflow\"][\"subworkflows\"][1][\"units\"][1][\"flowchartId\"]     band_gap_direct = raw_property_endpoints.get_direct_band_gap(job[\"_id\"], unit_flowchart_id)     band_gap_indirect = raw_property_endpoints.get_indirect_band_gap(job[\"_id\"], unit_flowchart_id)     results.append(         {             \"initial_structure\": material,             \"final_structure\": final_structure,             \"pressure\": pressure,             \"band_gap_direct\": band_gap_direct,             \"band_gap_indirect\": band_gap_indirect,         }     ) In\u00a0[\u00a0]: Copied! <pre>table = []\nfor result in results:\n    data = flatten_material(result[\"initial_structure\"])\n    data.extend(flatten_material(result[\"initial_structure\"]))\n    data.extend([result[\"pressure\"], result[\"band_gap_direct\"], result[\"band_gap_indirect\"]])\n    table.append(data)\n</pre> table = [] for result in results:     data = flatten_material(result[\"initial_structure\"])     data.extend(flatten_material(result[\"initial_structure\"]))     data.extend([result[\"pressure\"], result[\"band_gap_direct\"], result[\"band_gap_indirect\"]])     table.append(data) In\u00a0[\u00a0]: Copied! <pre>headers = []\nkeys = [\"ID\", \"NAME\", \"TAGS\", \"NS\", \"LAT-A\", \"LAT-B\", \"LAT-C\", \"LAT-ALPHA\", \"LAT-BETA\", \"LAT-GAMMA\"]\nheaders.extend([\"-\".join((\"INI\", key)) for key in keys])\nheaders.extend([\"-\".join((\"FIN\", key)) for key in keys])\nheaders.extend([\"PRESSURE\", \"DIRECT-GAP\", \"INDIRECT-GAP\"])\n</pre> headers = [] keys = [\"ID\", \"NAME\", \"TAGS\", \"NS\", \"LAT-A\", \"LAT-B\", \"LAT-C\", \"LAT-ALPHA\", \"LAT-BETA\", \"LAT-GAMMA\"] headers.extend([\"-\".join((\"INI\", key)) for key in keys]) headers.extend([\"-\".join((\"FIN\", key)) for key in keys]) headers.extend([\"PRESSURE\", \"DIRECT-GAP\", \"INDIRECT-GAP\"]) <p>Create and print the final table as Pandas dataFrame.</p> In\u00a0[\u00a0]: Copied! <pre>df = pd.DataFrame(data=table, columns=headers)\nhtml = dataframe_to_html(df)\nhtml\n</pre> df = pd.DataFrame(data=table, columns=headers) html = dataframe_to_html(df) html"},{"location":"examples/job/run-simulations-and-extract-properties/#run-simulations-and-extract-properties","title":"Run Simulations and Extract Properties\u00b6","text":"<p>This example demonstrates how to use Mat3ra RESTful API to create simulation Jobs programmatically for multiple Materials at once and extract the resulting Properties forming a Pandas dataframe.</p> <p>This approach can work with any Workflows. For the demonstration purpose we use the Density Functional Theory and extract Electronic Band Gap as the property of interest.</p> <p>IMPORTANT NOTE: In order to run this example in full, an active Mat3ra.com account with access to VASP (Vienna ab-initio simulations package) is required. Alternatively, Readers may substitute the workflow ID below with another one (an equivalent one for Quantum ESPRESSO, for example) and adjust extraction of the results (\"Extract results\" section). RESTful API credentials shall be updated in settings.</p>"},{"location":"examples/job/run-simulations-and-extract-properties/#steps","title":"Steps\u00b6","text":"<p>We follow the below steps:</p> <ul> <li><p>Import materials from materials project</p> </li> <li><p>Group imported materials inside a materials set</p> </li> <li><p>Create jobs for the materials and grouping them inside a jobs set</p> </li> <li><p>Submit jobs and monitoring the progress</p> </li> <li><p>Extract the final structure (relaxed structure) and its properties</p> </li> <li><p>Output the results as Pandas dataFrame</p> </li> </ul>"},{"location":"examples/job/run-simulations-and-extract-properties/#pre-requisites","title":"Pre-requisites\u00b6","text":"<p>The explanation below assumes that the reader is familiar with the concepts used in Mat3ra platform and RESTful API. We outline these below and direct the reader to the original sources of information:</p> <ul> <li>Generating RESTful API authentication parameters</li> <li>Importing materials from materials project</li> <li>Creating and submitting jobs</li> </ul>"},{"location":"examples/job/run-simulations-and-extract-properties/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/job/run-simulations-and-extract-properties/#import-packages","title":"Import packages\u00b6","text":""},{"location":"examples/job/run-simulations-and-extract-properties/#materials","title":"Materials\u00b6","text":"<ul> <li>MATERIALS_PROJECT_IDS: a list of material IDs to be imported from materials project</li> <li>TAGS: a list of tags to assign to imported materials</li> <li>MATERIALS_SET_NAME: the name of the materials set</li> </ul>"},{"location":"examples/job/run-simulations-and-extract-properties/#jobs","title":"Jobs\u00b6","text":"<p>Parameters for the jobs to be ran for the imported materials:</p> <ul> <li>JOB_NAME_PREFIX: prefix to be used for the job name with \"{JOB_NAME_PREFIX} {FORMULA}\" convention (e.g.  \"Job Name Prefix - SiGe\")</li> <li>JOBS_SET_NAME: the name of the jobs set</li> </ul>"},{"location":"examples/job/run-simulations-and-extract-properties/#workflow","title":"Workflow\u00b6","text":"<p>This example is based on this bank workflow which is later copied to the account workflows collection.  The workflow is named \"D3-GGA-BS-BG-DOS-ALL\" and utilizes the logic explained in https://arxiv.org/pdf/1808.05325.pdf, for example (see section \"Methodology\", Table I). \"D3\" indicates the difficulty level 3 per the table convention. BS, BG, DOS indicate the properties extracted - Band Structure, Band Gap, Density of States. The workflow is utilizing VASP simulation engine at version 5.4.4.</p>"},{"location":"examples/job/run-simulations-and-extract-properties/#compute","title":"Compute\u00b6","text":"<p>Setup compute parameters. See this for more information about compute parameters.</p> <ul> <li>NODES: Number of nodes. Defaults to 1.</li> <li>PPN: Number of MPI processes per each node, Defaults to 1.</li> <li>QUEUE: The name of queue to submit the jobs into. Defaults to D.</li> <li>TIME_LIMIT: Job walltime. Defaults to \"01:00:00\" (one hour).</li> <li>CLUSTER: The full qualified domain name (FQDN) or alias of the cluster to submit the jobs into.</li> </ul> <p>explain in the notebook that the job might run out of the limit of memory so it is clear, (2) suggest using OR queue to avoid memory limitations</p> <p>NOTE: Although here we set the QUEUE to be debug, it is possible the job might run out of memory, and result in an Errored-Jobs status. If this happens, we suggest you switch from <code>QUEUE = D</code> to <code>QUEUE = OR</code> to avoid memory limitations.</p>"},{"location":"examples/job/run-simulations-and-extract-properties/#initialize-endpoints","title":"Initialize endpoints\u00b6","text":""},{"location":"examples/job/run-simulations-and-extract-properties/#create-workflow","title":"Create workflow\u00b6","text":"<p>Copy bank workflow (template) to the account's workflows collection.</p>"},{"location":"examples/job/run-simulations-and-extract-properties/#import-materials","title":"Import materials\u00b6","text":"<p>Import materials from materials project with the above tags.</p>"},{"location":"examples/job/run-simulations-and-extract-properties/#create-jobs","title":"Create jobs\u00b6","text":"<p>Create jobs for the materials above.</p>"},{"location":"examples/job/run-simulations-and-extract-properties/#extract-results","title":"Extract results\u00b6","text":"<p>For each material, simulaion job, final structure, pressure and band gaps are extracted.</p> <ul> <li><p>Final structure and pressure are extracted from the first unit (vasp_relax with index 0) of the first job's subworkflow (volume-relaxation with index 0)</p> </li> <li><p>Band gaps are extracted from the second unit (vasp-bands with index 1) of the second job's subworkflow (SCF-BS-BG-DOS with index 1).</p> </li> </ul>"},{"location":"examples/job/run-simulations-and-extract-properties/#flatten-results","title":"Flatten results\u00b6","text":"<p>The below for-loop iterates over the results and flatten them to form the final Pandas dataFrame.</p>"},{"location":"examples/job/run-simulations-and-extract-properties/#output-results","title":"Output results\u00b6","text":"<p>Form the Pandas dataFrame headers according to the table generated above with the following abbreviations:</p> <ul> <li>\"INI\": INITIAL</li> <li>\"FIN\": FINAL</li> <li>\"N-SITES\": Number of Sites</li> <li>\"LAT\": LATTICE</li> </ul>"},{"location":"examples/material/api_interoperability_showcase/","title":"Interoperability between Mat3ra and Materials Project","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[2]: Copied! <pre>from utils.settings import ENDPOINT_ARGS, MATERIALS_PROJECT_API_KEY\nfrom utils.generic import display_JSON\n\nimport ase.io\nfrom pymatgen.ext.matproj import MPRester\n\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\n</pre> from utils.settings import ENDPOINT_ARGS, MATERIALS_PROJECT_API_KEY from utils.generic import display_JSON  import ase.io from pymatgen.ext.matproj import MPRester  from exabyte_api_client.endpoints.materials import MaterialEndpoints <pre>/opt/hostedtoolcache/Python/3.8.17/x64/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> In\u00a0[3]: Copied! <pre>materials_project_api = MPRester(MATERIALS_PROJECT_API_KEY)\niron_oxides_ids = materials_project_api.get_materials_ids(\"Fe-O\")\n\nprint(iron_oxides_ids)\n</pre> materials_project_api = MPRester(MATERIALS_PROJECT_API_KEY) iron_oxides_ids = materials_project_api.get_materials_ids(\"Fe-O\")  print(iron_oxides_ids) <pre>/opt/hostedtoolcache/Python/3.8.17/x64/lib/python3.8/site-packages/pymatgen/ext/matproj.py:186: UserWarning: You are using the legacy MPRester. This version of the MPRester will no longer be updated. To access the latest data with the new MPRester, obtain a new API key from https://materialsproject.org/api and consult the docs at https://docs.materialsproject.org/ for more information.\n  warnings.warn(\n</pre> <pre>['mp-1271693', 'mp-136', 'mp-1271562', 'mp-1245108', 'mp-1096950', 'mp-1194030', 'mp-568345', 'mp-1271295', 'mp-13', 'mp-150', 'mp-540003', 'mp-1244911', 'mp-1181437', 'mp-705416', 'mp-764417', 'mp-1456', 'mp-32939', 'mp-1245078', 'mp-1103327', 'mp-763787', 'mp-1205415', 'mp-705555', 'mp-705588', 'mp-1062652', 'mp-705558', 'mp-715811', 'mvc-15135', 'mp-1068212', 'mp-1283030', 'mp-510252', 'mp-25332', 'mp-1224936', 'mp-849689', 'mp-1225007', 'mp-1244983', 'mp-1181411', 'mp-1195927', 'mp-530050', 'mvc-13234', 'mp-776135', 'mp-1279742', 'mp-715572', 'mp-1181334', 'mp-776606', 'mp-759037', 'mp-1245084', 'mp-1284941', 'mp-1188678', 'mp-1181657', 'mp-715614', 'mp-715558', 'mp-757565', 'mp-510080', 'mp-705424', 'mp-19770', 'mp-530048', 'mp-705414', 'mp-1095382', 'mp-1178247', 'mp-1194978', 'mp-650112', 'mp-505595', 'mp-756436', 'mp-557546', 'mvc-12205', 'mp-612405', 'mp-715276', 'mp-1178232', 'mvc-11541', 'mp-705753', 'mp-19306', 'mp-716814', 'mp-1291630', 'mp-715333', 'mp-542896', 'mp-1178239', 'mp-754765', 'mvc-12905', 'mp-1078361', 'mp-715262', 'mp-716052', 'mp-1178392', 'mp-1277436', 'mp-694910', 'mp-705553', 'mp-1224855', 'mvc-5967', 'mp-714904', 'mp-1182503', 'mp-1181766', 'mvc-10966', 'mp-1182229', 'mp-706875', 'mp-1181340', 'mp-25236', 'mp-1185276', 'mp-759504', 'mp-1245001', 'mp-510746', 'mvc-11999', 'mp-685153', 'mp-1205429', 'mp-1097003', 'mvc-13181', 'mp-1181570', 'mp-1245277', 'mp-715438', 'mvc-11993', 'mp-863766', 'mp-756693', 'mp-755189', 'mp-1245019', 'mp-565814', 'mvc-12204', 'mvc-12063', 'mvc-12125', 'mp-1181546', 'mp-863316', 'mp-705417', 'mp-1192788', 'mp-1245168', 'mp-705551', 'mp-18731', 'mvc-14925', 'mp-1184320', 'mvc-12039', 'mp-850222', 'mp-715275', 'mp-705547', 'mp-31770', 'mp-1244869', 'mp-611817', 'mp-1181813', 'mp-18905', 'mp-753682', 'mp-1225001', 'mp-764326', 'mp-1245154', 'mp-1182249', 'mvc-12005', 'mp-610917', 'mp-1091399', 'mp-1058623', 'mp-1180064', 'mp-1023923', 'mp-1102442', 'mp-560602', 'mp-1180036', 'mp-12957', 'mp-1087546', 'mp-1009490', 'mp-607540', 'mp-1056059', 'mp-1066100', 'mp-1056831', 'mp-1180008', 'mp-1180050', 'mp-611836', 'mp-1057818', 'mp-1065697']\n</pre> In\u00a0[4]: Copied! <pre># As a demonstration, take the first 10 iron oxides\nsome_iron_oxides = iron_oxides_ids[:10]\nprint(some_iron_oxides)\n</pre> # As a demonstration, take the first 10 iron oxides some_iron_oxides = iron_oxides_ids[:10] print(some_iron_oxides) <pre>['mp-1271693', 'mp-136', 'mp-1271562', 'mp-1245108', 'mp-1096950', 'mp-1194030', 'mp-568345', 'mp-1271295', 'mp-13', 'mp-150']\n</pre> In\u00a0[5]: Copied! <pre># Upload the first 10 iron oxides found to our account\nexabyte_materials_api = MaterialEndpoints(*ENDPOINT_ARGS)\nmaterials = exabyte_materials_api.import_from_materialsproject(MATERIALS_PROJECT_API_KEY, some_iron_oxides)\n</pre> # Upload the first 10 iron oxides found to our account exabyte_materials_api = MaterialEndpoints(*ENDPOINT_ARGS) materials = exabyte_materials_api.import_from_materialsproject(MATERIALS_PROJECT_API_KEY, some_iron_oxides) <p>Finally, it is always useful to stay organized. Materials sets make this convenient, acting as a folder to keep a group of related materials in. This would be especially helpful if, in the future, we wanted run a calculation over all the oxides we found in this example.</p> In\u00a0[6]: Copied! <pre># Move the iron oxides to a materials set, just for this example\nmaterials_set = exabyte_materials_api.create_set({\"name\": \"Some Iron Oxides\"})\nfor material in materials:\n    exabyte_materials_api.move_to_set(material[\"_id\"], \"\", materials_set[\"_id\"])\n</pre> # Move the iron oxides to a materials set, just for this example materials_set = exabyte_materials_api.create_set({\"name\": \"Some Iron Oxides\"}) for material in materials:     exabyte_materials_api.move_to_set(material[\"_id\"], \"\", materials_set[\"_id\"])"},{"location":"examples/material/api_interoperability_showcase/#overview","title":"Overview\u00b6","text":"<p>This example was created as part of our Advanced Topics Webinar on February 19, 2021. This webinar focused on explaining our API in detail, and provided examples of many areas of its functionality.</p> <p>In this notebook, we showcase a major advantage of APIs: interoperability. We begin by performing a query using the Materials Project API for all systems containing Iron and Oxygen. We then filter our results (for demonstraiton purposes, we keep only the first 10 materials found). Finally, we upload our results to the Mat3ra platform, where further calculations could be performed to characterize these materials.</p>"},{"location":"examples/material/api_interoperability_showcase/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/material/api_interoperability_showcase/#imports","title":"Imports\u00b6","text":""},{"location":"examples/material/api_interoperability_showcase/#query-the-materials-project","title":"Query the Materials Project\u00b6","text":"<p>We begin by using the Materials Project API implemented in PyMatGen to perform a query for all systems containing Iron and Oxygen.</p>"},{"location":"examples/material/api_interoperability_showcase/#query-materials-project-for-all-systems-containing-iron-and-oxygen","title":"Query Materials Project for all systems containing Iron and Oxygen\u00b6","text":""},{"location":"examples/material/api_interoperability_showcase/#filtering-the-results","title":"Filtering the Results\u00b6","text":"<p>This returns a lot of materials - 160 to be exact! In many cases, it is useful to filter down the number of materials. For example, we may want to exclude large unit cells that may be computationally intensive to study. Or we may want to restrict our results to only thermodynamically-stable oxides, by use of the material's energy above hull.</p> <p>As a basic example, here we only keep the first 10 iron oxides that the Materials Project API returned to us, and discard the other 150.</p>"},{"location":"examples/material/api_interoperability_showcase/#bringing-materials-into-the-user-account","title":"Bringing Materials Into the User Account\u00b6","text":"<p>Now that we have filtered the results from Materials Project down to just 10 structures, we may want to study them further with the computational models provided by Mat3ra. For example, we may be interested in leveraging a DFT code to find the structure with the largest band-gap, or perhaps we want to conduct a high-throughput screening of each material's surface energies.</p>"},{"location":"examples/material/create_material/","title":"Create Material","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[2]: Copied! <pre>from utils.settings import ENDPOINT_ARGS\nfrom utils.generic import display_JSON\n\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\n</pre> from utils.settings import ENDPOINT_ARGS from utils.generic import display_JSON  from exabyte_api_client.endpoints.materials import MaterialEndpoints In\u00a0[3]: Copied! <pre>CONFIG = {\n    \"name\": \"TEST MATERIAL\",\n    \"basis\": {\n        \"elements\": [{\"id\": 1, \"value\": \"Si\"}, {\"id\": 2, \"value\": \"Si\"}],\n        \"coordinates\": [{\"id\": 1, \"value\": [0, 0, 0]}, {\"id\": 2, \"value\": [0.25, 0.25, 0.25]}],\n        \"units\": \"crystal\",\n        \"name\": \"basis\",\n    },\n    \"lattice\": {\n        \"type\": \"FCC\",\n        \"a\": 3.867,\n        \"b\": 3.867,\n        \"c\": 3.867,\n        \"alpha\": 60,\n        \"beta\": 60,\n        \"gamma\": 60,\n        \"units\": {\"length\": \"angstrom\", \"angle\": \"degree\"},\n        \"vectors\": {\n            \"a\": [3.867, 0, 0],\n            \"b\": [1.9335000000000004, 3.348920236434424, 0],\n            \"c\": [1.9335000000000004, 1.1163067454781415, 3.1573922784475164],\n            \"name\": \"lattice vectors\",\n            \"alat\": 1,\n            \"units\": \"angstrom\",\n        },\n    },\n    \"tags\": [\"REST API\"],\n}\n</pre> CONFIG = {     \"name\": \"TEST MATERIAL\",     \"basis\": {         \"elements\": [{\"id\": 1, \"value\": \"Si\"}, {\"id\": 2, \"value\": \"Si\"}],         \"coordinates\": [{\"id\": 1, \"value\": [0, 0, 0]}, {\"id\": 2, \"value\": [0.25, 0.25, 0.25]}],         \"units\": \"crystal\",         \"name\": \"basis\",     },     \"lattice\": {         \"type\": \"FCC\",         \"a\": 3.867,         \"b\": 3.867,         \"c\": 3.867,         \"alpha\": 60,         \"beta\": 60,         \"gamma\": 60,         \"units\": {\"length\": \"angstrom\", \"angle\": \"degree\"},         \"vectors\": {             \"a\": [3.867, 0, 0],             \"b\": [1.9335000000000004, 3.348920236434424, 0],             \"c\": [1.9335000000000004, 1.1163067454781415, 3.1573922784475164],             \"name\": \"lattice vectors\",             \"alat\": 1,             \"units\": \"angstrom\",         },     },     \"tags\": [\"REST API\"], } In\u00a0[4]: Copied! <pre>endpoint = MaterialEndpoints(*ENDPOINT_ARGS)\nmaterial = endpoint.create(CONFIG)\n</pre> endpoint = MaterialEndpoints(*ENDPOINT_ARGS) material = endpoint.create(CONFIG) In\u00a0[5]: Copied! <pre>display_JSON(material)\n</pre> display_JSON(material)"},{"location":"examples/material/create_material/#overview","title":"Overview\u00b6","text":"<p>In this example we create a material from a JSON config with tags to identify the material.</p>"},{"location":"examples/material/create_material/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/material/create_material/#imports","title":"Imports\u00b6","text":""},{"location":"examples/material/create_material/#create-material-config","title":"Create material config\u00b6","text":"<p>Create material config in JSON format. See Material endpoint for more information about material config format.</p>"},{"location":"examples/material/create_material/#create-material","title":"Create material\u00b6","text":"<p>Initialize <code>MaterialEndpoints</code> class and call <code>create</code> function to create material.</p>"},{"location":"examples/material/create_material/#print-new-material","title":"Print new material\u00b6","text":""},{"location":"examples/material/get_materials_by_formula/","title":"Get Materials by Formula","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[2]: Copied! <pre>from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID\nfrom utils.generic import display_JSON\n\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\n</pre> from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID from utils.generic import display_JSON  from exabyte_api_client.endpoints.materials import MaterialEndpoints In\u00a0[3]: Copied! <pre>QUERY = {\"formula\": \"Si\", \"owner._id\": ACCOUNT_ID}\n</pre> QUERY = {\"formula\": \"Si\", \"owner._id\": ACCOUNT_ID} In\u00a0[4]: Copied! <pre>endpoint = MaterialEndpoints(*ENDPOINT_ARGS)\n</pre> endpoint = MaterialEndpoints(*ENDPOINT_ARGS) In\u00a0[5]: Copied! <pre>materials = endpoint.list(QUERY)\n</pre> materials = endpoint.list(QUERY) In\u00a0[6]: Copied! <pre>display_JSON(materials)\n</pre> display_JSON(materials)"},{"location":"examples/material/get_materials_by_formula/#overview","title":"Overview\u00b6","text":"<p>Inside this example we contact Material endpoint to obtain a list materials that an account has access to. We use chemical formula to filter the list.</p>"},{"location":"examples/material/get_materials_by_formula/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/material/get_materials_by_formula/#imports","title":"Imports\u00b6","text":""},{"location":"examples/material/get_materials_by_formula/#set-parameters","title":"Set Parameters\u00b6","text":"<ul> <li>QUERY: A query describing the documents to find. See Meteor collection for more information.</li> </ul>"},{"location":"examples/material/get_materials_by_formula/#initialize-the-endpoint","title":"Initialize the endpoint\u00b6","text":""},{"location":"examples/material/get_materials_by_formula/#list-materials","title":"List materials\u00b6","text":"<p>Contact the endpoint to list materials according to the query above.</p>"},{"location":"examples/material/get_materials_by_formula/#print-materials","title":"Print materials\u00b6","text":"<p>Print the list of materials saved under the corresponding variable in pretty JSON below.</p>"},{"location":"examples/material/import_materials_from_materialsproject/","title":"Import Materials from Materials Project","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[2]: Copied! <pre>from utils.settings import ENDPOINT_ARGS, MATERIALS_PROJECT_API_KEY\nfrom utils.generic import display_JSON\n\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\n</pre> from utils.settings import ENDPOINT_ARGS, MATERIALS_PROJECT_API_KEY from utils.generic import display_JSON  from exabyte_api_client.endpoints.materials import MaterialEndpoints In\u00a0[3]: Copied! <pre>MATERIALS_PROJECT_IDS = [\"mp-978534\", \"mp-1096549\"]\nTAGS = [\"tag1\", \"tag2\"]\n</pre> MATERIALS_PROJECT_IDS = [\"mp-978534\", \"mp-1096549\"] TAGS = [\"tag1\", \"tag2\"] In\u00a0[4]: Copied! <pre>endpoint = MaterialEndpoints(*ENDPOINT_ARGS)\nmaterials = endpoint.import_from_materialsproject(MATERIALS_PROJECT_API_KEY, MATERIALS_PROJECT_IDS, tags=TAGS)\n</pre> endpoint = MaterialEndpoints(*ENDPOINT_ARGS) materials = endpoint.import_from_materialsproject(MATERIALS_PROJECT_API_KEY, MATERIALS_PROJECT_IDS, tags=TAGS) In\u00a0[5]: Copied! <pre>display_JSON(materials)\n</pre> display_JSON(materials)"},{"location":"examples/material/import_materials_from_materialsproject/#overview","title":"Overview\u00b6","text":"<p>This example demonstrates how to import materials from the materials project database via Material endpoint.</p>"},{"location":"examples/material/import_materials_from_materialsproject/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/material/import_materials_from_materialsproject/#imports","title":"Imports\u00b6","text":""},{"location":"examples/material/import_materials_from_materialsproject/#set-parameters","title":"Set Parameters\u00b6","text":"<ul> <li><p>MATERIALS_PROJECT_IDS: a list of material IDs to be imported</p> </li> <li><p>TAGS: a list of tags to assign to imported materials</p> </li> </ul>"},{"location":"examples/material/import_materials_from_materialsproject/#import-materials","title":"Import materials\u00b6","text":"<p>Initialize <code>MaterialEndpoints</code> class and call <code>import_from_materialsproject</code> function to import materials.</p>"},{"location":"examples/material/import_materials_from_materialsproject/#print-imported-materials","title":"Print imported materials\u00b6","text":"<p>Print the list of imported materials in pretty JSON below.</p>"},{"location":"examples/material/import_materials_from_poscar/","title":"Import Materials from Poscar","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; export IS_USING_GIT_LFS=true; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n    from examples.utils.notebook import get_notebook_info\n\n    os.chdir(os.path.join(\"api-examples\", os.path.dirname(get_notebook_info()[\"notebook_path\"])))\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; export IS_USING_GIT_LFS=true; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash     from examples.utils.notebook import get_notebook_info      os.chdir(os.path.join(\"api-examples\", os.path.dirname(get_notebook_info()[\"notebook_path\"]))) In\u00a0[2]: Copied! <pre>from utils.settings import ENDPOINT_ARGS\nfrom utils.generic import display_JSON\n\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\n</pre> from utils.settings import ENDPOINT_ARGS from utils.generic import display_JSON  from exabyte_api_client.endpoints.materials import MaterialEndpoints In\u00a0[3]: Copied! <pre>NAME = \"My Material\"\nPOSCAR_PATH = \"../assets/mp-978534.poscar\"\n</pre> NAME = \"My Material\" POSCAR_PATH = \"../assets/mp-978534.poscar\" In\u00a0[4]: Copied! <pre>content = \"\"\nwith open(POSCAR_PATH) as f:\n    content = f.read()\n    print(content)\n\nendpoint = MaterialEndpoints(*ENDPOINT_ARGS)\nmaterial = endpoint.import_from_file(NAME, content)\n</pre> content = \"\" with open(POSCAR_PATH) as f:     content = f.read()     print(content)  endpoint = MaterialEndpoints(*ENDPOINT_ARGS) material = endpoint.import_from_file(NAME, content) <pre>mp-978534\n1.0\n   3.940618000\t   0.000000000\t   0.000000000\n  -1.970309000\t   3.412675295\t   0.000000000\n   0.000000000\t   0.000000000\t   6.508731000\nGe Si\n2 2\ndirect\n   0.000000000    0.000000000    0.000000000 Ge\n   0.333334000    0.666666000    0.500439000 Ge\n   0.000000000    0.000000000    0.374560000 Si\n   0.333334000    0.666666000    0.874561000 Si\n</pre> In\u00a0[5]: Copied! <pre>display_JSON(material)\n</pre> display_JSON(material)"},{"location":"examples/material/import_materials_from_poscar/#overview","title":"Overview\u00b6","text":"<p>This example demonstrates how to import a material from a POSCAR file via Material endpoints.</p>"},{"location":"examples/material/import_materials_from_poscar/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/material/import_materials_from_poscar/#imports","title":"Imports\u00b6","text":""},{"location":"examples/material/import_materials_from_poscar/#set-parameters","title":"Set Parameters\u00b6","text":"<ul> <li>NAME: material name</li> <li>POSCAR_PATH: absolute path to the POSCAR file</li> </ul>"},{"location":"examples/material/import_materials_from_poscar/#import-material","title":"Import material\u00b6","text":"<p>Initialize <code>MaterialEndpoints</code> class and call <code>import_from_file</code> function to import the material.</p>"},{"location":"examples/material/import_materials_from_poscar/#print-imported-material","title":"Print imported material\u00b6","text":"<p>Print the list of imported materials in pretty JSON below.</p>"},{"location":"examples/system/get_authentication_params/","title":"Get Authentication Params","text":"In\u00a0[\u00a0]: Copied! <pre># @title Authorization Form\nUSERNAME = \"YOUR_USERNAME\"  # @param {type:\"string\"}\n\n# avoid storing password in plaintext\nfrom getpass import getpass\n\nPASSWORD = getpass(\"Please enter password: \")\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form USERNAME = \"YOUR_USERNAME\"  # @param {type:\"string\"}  # avoid storing password in plaintext from getpass import getpass  PASSWORD = getpass(\"Please enter password: \")  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[\u00a0]: Copied! <pre>from utils.settings import HOST, PORT, VERSION, SECURE\nfrom utils.generic import display_JSON\n\nfrom exabyte_api_client.endpoints.login import LoginEndpoint\n</pre> from utils.settings import HOST, PORT, VERSION, SECURE from utils.generic import display_JSON  from exabyte_api_client.endpoints.login import LoginEndpoint In\u00a0[\u00a0]: Copied! <pre>endpoint = LoginEndpoint(HOST, PORT, USERNAME, PASSWORD, VERSION, SECURE)\nauth_params = endpoint.login()\n</pre> endpoint = LoginEndpoint(HOST, PORT, USERNAME, PASSWORD, VERSION, SECURE) auth_params = endpoint.login() In\u00a0[\u00a0]: Copied! <pre>display_JSON(auth_params)\n</pre> display_JSON(auth_params)"},{"location":"examples/system/get_authentication_params/#overview","title":"Overview\u00b6","text":"<p>This example shows how to log in to Mat3ra RESTFul API via Login endpoint and generate API authentication parameters. Note that it is also possible to generate an API token manually via platform web UI as described in the project README.</p>"},{"location":"examples/system/get_authentication_params/#execution","title":"Execution\u00b6","text":"<p>NOTE: In order to run this example, an active Mat3ra.com account is required.</p>"},{"location":"examples/system/get_authentication_params/#set-parameters","title":"Set Parameters\u00b6","text":"<ul> <li><p>USERNAME: Your Mat3ra account username.</p> </li> <li><p>PASSWORD: Your Mat3ra account password.</p> </li> </ul>"},{"location":"examples/system/get_authentication_params/#import-packages","title":"Import packages\u00b6","text":""},{"location":"examples/system/get_authentication_params/#initialize-the-endpoint","title":"Initialize the endpoint\u00b6","text":""},{"location":"examples/system/get_authentication_params/#print-authentication-parameters","title":"Print authentication parameters\u00b6","text":"<p>Print the authentication parameters in pretty JSON below. Update settings with this parameters to be able to run other examples.</p>"},{"location":"examples/workflow/get_workflows/","title":"Get Workflows","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[2]: Copied! <pre>from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID\nfrom utils.generic import display_JSON\n\nfrom exabyte_api_client.endpoints.workflows import WorkflowEndpoints\n</pre> from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID from utils.generic import display_JSON  from exabyte_api_client.endpoints.workflows import WorkflowEndpoints In\u00a0[3]: Copied! <pre>QUERY = {\"name\": \"Total Energy\", \"owner._id\": ACCOUNT_ID}\n\nOPTIONS = {\"limit\": 2}\n</pre> QUERY = {\"name\": \"Total Energy\", \"owner._id\": ACCOUNT_ID}  OPTIONS = {\"limit\": 2} In\u00a0[4]: Copied! <pre>endpoint = WorkflowEndpoints(*ENDPOINT_ARGS)\n</pre> endpoint = WorkflowEndpoints(*ENDPOINT_ARGS) In\u00a0[5]: Copied! <pre>workflows = endpoint.list(QUERY, OPTIONS)\n</pre> workflows = endpoint.list(QUERY, OPTIONS) In\u00a0[6]: Copied! <pre>display_JSON(workflows)\n</pre> display_JSON(workflows)"},{"location":"examples/workflow/get_workflows/#overview","title":"Overview\u00b6","text":"<p>Inside this example we contact Workflow endpoint to obtain a list of workflows that an account has access to.</p>"},{"location":"examples/workflow/get_workflows/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/workflow/get_workflows/#imports","title":"Imports\u00b6","text":""},{"location":"examples/workflow/get_workflows/#set-parameters","title":"Set Parameters\u00b6","text":"<ul> <li><p>QUERY: A query describing the documents to find. See Meteor collection for more information.</p> </li> <li><p>limit: Maximum number of results to return. See Meteor collection for more information.</p> </li> </ul>"},{"location":"examples/workflow/get_workflows/#initialize-the-endpoint","title":"Initialize the endpoint\u00b6","text":"<p>Initialize a helper class to interact with <code>WorkflowEndpoints</code>. This only has to be done once.</p>"},{"location":"examples/workflow/get_workflows/#list-workflows","title":"List workflows\u00b6","text":"<p>Contact the endpoint to list workflows according to the query above.</p>"},{"location":"examples/workflow/get_workflows/#print-workflows","title":"Print workflows\u00b6","text":"<p>Print the list of workflows saved under the corresponding variable in pretty JSON below.</p>"},{"location":"examples/workflow/qe_scf_calculation/","title":"Quantum Espresso Workflow and Job","text":"In\u00a0[1]: Copied! <pre># @title Authorization Form\nACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\nAUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\nMATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"}\nORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n\nimport os\n\nif \"COLAB_JUPYTER_IP\" in os.environ:\n    os.environ.update(\n        dict(\n            ACCOUNT_ID=ACCOUNT_ID,\n            AUTH_TOKEN=AUTH_TOKEN,\n            MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,\n            ORGANIZATION_ID=ORGANIZATION_ID,\n        )\n    )\n\n    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n</pre> # @title Authorization Form ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"} AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"} MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\"  # @param {type:\"string\"} ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}  import os  if \"COLAB_JUPYTER_IP\" in os.environ:     os.environ.update(         dict(             ACCOUNT_ID=ACCOUNT_ID,             AUTH_TOKEN=AUTH_TOKEN,             MATERIALS_PROJECT_API_KEY=MATERIALS_PROJECT_API_KEY,             ORGANIZATION_ID=ORGANIZATION_ID,         )     )      !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash In\u00a0[2]: Copied! <pre>from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID\nfrom utils.generic import wait_for_jobs_to_finish\n\nfrom exabyte_api_client.endpoints.workflows import WorkflowEndpoints\nfrom exabyte_api_client.endpoints.materials import MaterialEndpoints\nfrom exabyte_api_client.endpoints.jobs import JobEndpoints\n</pre> from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID from utils.generic import wait_for_jobs_to_finish  from exabyte_api_client.endpoints.workflows import WorkflowEndpoints from exabyte_api_client.endpoints.materials import MaterialEndpoints from exabyte_api_client.endpoints.jobs import JobEndpoints In\u00a0[3]: Copied! <pre># Initialize a helper class to interact with WorkflowEndpoints\nworkflow_endpoints = WorkflowEndpoints(*ENDPOINT_ARGS)\nmaterial_endpoints = MaterialEndpoints(*ENDPOINT_ARGS)\njob_endpoints = JobEndpoints(*ENDPOINT_ARGS)\n</pre> # Initialize a helper class to interact with WorkflowEndpoints workflow_endpoints = WorkflowEndpoints(*ENDPOINT_ARGS) material_endpoints = MaterialEndpoints(*ENDPOINT_ARGS) job_endpoints = JobEndpoints(*ENDPOINT_ARGS) In\u00a0[4]: Copied! <pre># user modifiable part\nscript = r\"\"\"#!/bin/bash\n\n# switch to the job working directory\ncd $PBS_O_WORKDIR\n\n# ----------------------- QUANTUM ESPRESSO INPUT FILE ------------------------ #\ncat &gt; pw.in &lt;&lt; EOF\n&amp;CONTROL\n  calculation = 'scf',\n  prefix = 'silicon',\n  outdir = './tmp/'\n  pseudo_dir = './'\n/\n\n&amp;SYSTEM\n  ibrav =  2,\n  celldm(1) = 10.26,\n  nat =  2,\n  ntyp = 1,\n  ecutwfc = 30\n  nbnd = 8\n/\n\n&amp;ELECTRONS\n  conv_thr = 1e-8,\n  mixing_beta = 0.6\n/\n\nATOMIC_SPECIES\n  Si 28.086 Si.pz-vbc.UPF\n\nATOMIC_POSITIONS (alat)\n  Si 0.0 0.0 0.0\n  Si 0.25 0.25 0.25\n\nK_POINTS (automatic)\n  7 7 7 0 0 0\nEOF\n# -------------------------- PSEUDO POTENTIAL FILE --------------------------- #\n# provide a downloadable link for the pseudo potential file\nwget https://media.githubusercontent.com/media/exabyte-io/api-examples/dev/examples/assets/Si.pz-vbc.UPF\n# --------------------------------- RUN JOB ---------------------------------- #\n# load required module\nmodule add espresso/63-i-174-impi-044\n\nmpirun -np $PBS_NP pw.x -in pw.in | tee pw.out\n\"\"\"\n</pre> # user modifiable part script = r\"\"\"#!/bin/bash  # switch to the job working directory cd $PBS_O_WORKDIR  # ----------------------- QUANTUM ESPRESSO INPUT FILE ------------------------ # cat &gt; pw.in &lt;&lt; EOF &amp;CONTROL   calculation = 'scf',   prefix = 'silicon',   outdir = './tmp/'   pseudo_dir = './' /  &amp;SYSTEM   ibrav =  2,   celldm(1) = 10.26,   nat =  2,   ntyp = 1,   ecutwfc = 30   nbnd = 8 /  &amp;ELECTRONS   conv_thr = 1e-8,   mixing_beta = 0.6 /  ATOMIC_SPECIES   Si 28.086 Si.pz-vbc.UPF  ATOMIC_POSITIONS (alat)   Si 0.0 0.0 0.0   Si 0.25 0.25 0.25  K_POINTS (automatic)   7 7 7 0 0 0 EOF # -------------------------- PSEUDO POTENTIAL FILE --------------------------- # # provide a downloadable link for the pseudo potential file wget https://media.githubusercontent.com/media/exabyte-io/api-examples/dev/examples/assets/Si.pz-vbc.UPF # --------------------------------- RUN JOB ---------------------------------- # # load required module module add espresso/63-i-174-impi-044  mpirun -np $PBS_NP pw.x -in pw.in | tee pw.out \"\"\" In\u00a0[5]: Copied! <pre># populate workflow from a template\nimport json\n\nwith open(\"../assets/bash_workflow_template.json\", \"r\") as f:\n    WORKFLOW_BODY = json.load(f)\n\nWORKFLOW_BODY[\"subworkflows\"][0][\"units\"][0][\"input\"][0][\"content\"] = script\n</pre> # populate workflow from a template import json  with open(\"../assets/bash_workflow_template.json\", \"r\") as f:     WORKFLOW_BODY = json.load(f)  WORKFLOW_BODY[\"subworkflows\"][0][\"units\"][0][\"input\"][0][\"content\"] = script In\u00a0[6]: Copied! <pre># create workflow\nWORKFLOW_RESP = workflow_endpoints.create(WORKFLOW_BODY)\n</pre> # create workflow WORKFLOW_RESP = workflow_endpoints.create(WORKFLOW_BODY) In\u00a0[7]: Copied! <pre># job creation payload\nJOB_BODY = {\n    \"name\": \"SCF Calculation\",\n    \"compute\": {\"ppn\": 4, \"nodes\": 1, \"queue\": \"OR\"},\n    \"_project\": {\"slug\": \"pranab-default\"},\n    \"workflow\": WORKFLOW_RESP[\"_id\"],\n}\n</pre> # job creation payload JOB_BODY = {     \"name\": \"SCF Calculation\",     \"compute\": {\"ppn\": 4, \"nodes\": 1, \"queue\": \"OR\"},     \"_project\": {\"slug\": \"pranab-default\"},     \"workflow\": WORKFLOW_RESP[\"_id\"], } In\u00a0[8]: Copied! <pre># create job\nJOB_RESP = job_endpoints.create(JOB_BODY)\n</pre> # create job JOB_RESP = job_endpoints.create(JOB_BODY) In\u00a0[9]: Copied! <pre># TODO: NOT SUPPORTED YET, upload pseudo potential file\n# with open('../assets/Si.pz-vbc.UPF', 'r') as f:\n#     PP_FILE = f.read()\n#     data = json.dumps({\"files\": PP_FILE})\n#     FILE_RESP=job_endpoints.insert_output_files(JOB_RESP[\"_id\"], data)\n</pre> # TODO: NOT SUPPORTED YET, upload pseudo potential file # with open('../assets/Si.pz-vbc.UPF', 'r') as f: #     PP_FILE = f.read() #     data = json.dumps({\"files\": PP_FILE}) #     FILE_RESP=job_endpoints.insert_output_files(JOB_RESP[\"_id\"], data) In\u00a0[10]: Copied! <pre># submit job to run\njob_endpoints.submit(JOB_RESP[\"_id\"])\n</pre> # submit job to run job_endpoints.submit(JOB_RESP[\"_id\"]) In\u00a0[11]: Copied! <pre># monitor job and wait for it to be finished\nwait_for_jobs_to_finish(job_endpoints, [JOB_RESP[\"_id\"]], 30)\n</pre> # monitor job and wait for it to be finished wait_for_jobs_to_finish(job_endpoints, [JOB_RESP[\"_id\"]], 30) <pre>Wait for jobs to finish, poll interval: 30 sec\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:24:54 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:25:24 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:25:55 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:26:25 |                1 |             0 |               0 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n+---------------------+------------------+---------------+-----------------+----------------+\n|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n+=====================+==================+===============+=================+================+\n| 2023-07-28-15:26:56 |                0 |             0 |               1 |              0 |\n+---------------------+------------------+---------------+-----------------+----------------+\n</pre> In\u00a0[12]: Copied! <pre>files = job_endpoints.list_files(JOB_RESP[\"_id\"])\nfor file in files:\n    if file[\"name\"] == \"pw.out\":\n        output_file_metadata = file\n\nimport urllib\n\nserver_response = urllib.request.urlopen(output_file_metadata[\"signedUrl\"])\noutput_file_bytes = server_response.read()\noutput_file = output_file_bytes.decode(encoding=\"UTF-8\")\n</pre> files = job_endpoints.list_files(JOB_RESP[\"_id\"]) for file in files:     if file[\"name\"] == \"pw.out\":         output_file_metadata = file  import urllib  server_response = urllib.request.urlopen(output_file_metadata[\"signedUrl\"]) output_file_bytes = server_response.read() output_file = output_file_bytes.decode(encoding=\"UTF-8\") In\u00a0[13]: Copied! <pre>energy = []\nlen_energy = len(\"total energy\")\nfor line in output_file.split(\"\\n\"):\n    if line.strip().lstrip(\"!\")[:len_energy] == \"total energy\":\n        energy.append(float(line.split(\"=\")[1].rstrip(\"Ry\")))\n</pre> energy = [] len_energy = len(\"total energy\") for line in output_file.split(\"\\n\"):     if line.strip().lstrip(\"!\")[:len_energy] == \"total energy\":         energy.append(float(line.split(\"=\")[1].rstrip(\"Ry\"))) In\u00a0[14]: Copied! <pre># plot energy with iteration step\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nplt.plot(energy)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Energy (Ry)\")\nplt.show()\n</pre> # plot energy with iteration step import matplotlib.pyplot as plt  %matplotlib inline  plt.plot(energy) plt.xlabel(\"Number of iteration\") plt.ylabel(\"Energy (Ry)\") plt.show()"},{"location":"examples/workflow/qe_scf_calculation/#quantum-espresso-scf-calculation-via-api","title":"Quantum Espresso SCF calculation via API\u00b6","text":""},{"location":"examples/workflow/qe_scf_calculation/#complete-authorization-form-and-initialize-settings","title":"Complete Authorization Form and Initialize Settings\u00b6","text":"<p>This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.</p> <p>If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.</p> <p>ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to Mat3ra.com's API Endpoints.</p> <p>MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to Material Project's API</p> <p>ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/</p> <p>NOTE: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file settings.json if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/</p>"},{"location":"examples/workflow/qe_scf_calculation/#create-a-quantum-espresso-workflow-for-scf-calculation","title":"Create a Quantum Espresso workflow for SCF calculation\u00b6","text":"<p>Below we provide our Quantum Espresso input file via a bash script.</p> <p>Note that we provide the pseudo potential file via a downloadable url. We are working on supporting direct uploading of pseudo potential file from local file system, but it is currently not available. Below are some of the sources to find pseudo potentials:</p> <ul> <li>Pseudopotentials library at Quantum Espresso</li> <li>Standard solid-state pseudopotentials (SSSP) library</li> <li>Pseudo dojo library</li> <li>GBRV pseudo potential library</li> </ul>"},{"location":"examples/workflow/qe_scf_calculation/#create-and-submit-job","title":"Create and submit job\u00b6","text":"<p>Below user can specify the project name and compute parameters such as <code>queue</code>, number of <code>nodes</code> and number of processors <code>ppn</code> per node. Find more about compute parameters here.</p>"},{"location":"examples/workflow/qe_scf_calculation/#get-output-file-perform-post-processing-and-make-plots","title":"Get output file, perform post processing, and make plots\u00b6","text":""}]}
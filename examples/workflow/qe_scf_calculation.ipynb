{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5d1a592",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Exabyte-io/api-examples/blob/dev/examples/workflow/qe_scf_calculation.ipynb\" target=\"_parent\">\n",
    "<img alt=\"Open in Google Colab\" src=\"https://user-images.githubusercontent.com/20477508/128780728-491fea90-9b23-495f-a091-11681150db37.jpeg\" width=\"150\" border=\"0\">\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92673fc2-8999-415b-a866-7692a3e7d682",
   "metadata": {},
   "source": [
    "# Quantum Espresso SCF calculation via API\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41378265",
   "metadata": {},
   "source": [
    "# Complete Authorization Form and Initialize Settings\n",
    "\n",
    "This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.\n",
    "\n",
    "If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.\n",
    "\n",
    "ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to [Mat3ra.com's API Endpoints](https://docs.mat3ra.com/rest-api/endpoints/).\n",
    "\n",
    "ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/\n",
    "\n",
    "> <span style=\"color: orange\">**NOTE**</span>: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, and ORGANIZATION_ID should be set in the file [settings.json](../../utils/settings.json) if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/"
   ]
  },
  {
   "cell_type": "code",
   "id": "62f59cb7",
   "metadata": {},
   "source": [
    "# @title Authorization Form\n",
    "ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\n",
    "AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\n",
    "ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "if \"COLAB_JUPYTER_IP\" in os.environ:\n",
    "    os.environ.update(\n",
    "        dict(\n",
    "            ACCOUNT_ID=ACCOUNT_ID,\n",
    "            AUTH_TOKEN=AUTH_TOKEN,\n",
    "            ORGANIZATION_ID=ORGANIZATION_ID,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n",
    "\n",
    "if sys.platform == \"emscripten\":\n",
    "    apiConfig = data_from_host.get(\"apiConfig\")\n",
    "    os.environ.update(data_from_host.get(\"environ\", {}))\n",
    "    os.environ.update(\n",
    "        dict(\n",
    "            ACCOUNT_ID=apiConfig.get(\"accountId\"),\n",
    "            AUTH_TOKEN=apiConfig.get(\"authToken\"),\n",
    "            ORGANIZATION_ID=apiConfig.get(\"organizationId\", \"\"),\n",
    "            CLUSTERS=json.dumps(apiConfig.get(\"clusters\", [])),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    import micropip\n",
    "\n",
    "    await micropip.install(\"mat3ra-api-examples\", deps=False)\n",
    "    from utils.jupyterlite import install_packages\n",
    "\n",
    "    await install_packages(\"api_examples\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Compute\n",
    "\n",
    "Setup compute parameters. See [this](https://docs.mat3ra.com/infrastructure/compute/parameters/) for more information about compute parameters.\n",
    "\n",
    "- **CLUSTER_NAME**: The full qualified domain name (FQDN) or alias of the cluster to submit the jobs into.\n",
    "- **PPN**: Number of MPI processes per each node, Defaults to 1.\n",
    "- **NODES**: Number of nodes. Defaults to 1.\n",
    "- **QUEUE_NAME**: The name of queue to submit the jobs into. Defaults to \"D\".\n",
    "- **TIME_LIMIT**: Job walltime. Defaults to \"01:00:00\" (one hour).\n"
   ],
   "id": "5dca0feaf2c1b284"
  },
  {
   "metadata": {
    "id": "wiudje4-2Qxc"
   },
   "cell_type": "code",
   "source": [
    "# using the first available cluster and queue in the list\n",
    "cluster_config = next(iter(json.loads(os.getenv(\"CLUSTERS\"))), {})\n",
    "queue_configs = cluster_config.get(\"queues\", [])\n",
    "\n",
    "CLUSTER_NAME = cluster_config.get(\"displayName\", \"cluster-001\")\n",
    "PPN = 1\n",
    "NODES = 1\n",
    "QUEUE_NAME = next(iter(queue_configs), {}).get(\"NAME\", \"D\")\n",
    "TIME_LIMIT = \"01:00:00\""
   ],
   "id": "6b645d1149740c3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialize the endpoints",
   "id": "a2fe3a7420ec31c3"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID\n",
    "from utils.generic import wait_for_jobs_to_finish\n",
    "\n",
    "from exabyte_api_client.endpoints.workflows import WorkflowEndpoints\n",
    "from exabyte_api_client.endpoints.materials import MaterialEndpoints\n",
    "from exabyte_api_client.endpoints.jobs import JobEndpoints"
   ],
   "id": "504fd5dd-5411-4073-be50-62dd84baeb9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4e2b1f6-40be-4a7e-aa49-1fa36df4e33c",
   "metadata": {},
   "source": [
    "# Initialize a helper class to interact with WorkflowEndpoints\n",
    "workflow_endpoints = WorkflowEndpoints(*ENDPOINT_ARGS)\n",
    "material_endpoints = MaterialEndpoints(*ENDPOINT_ARGS)\n",
    "job_endpoints = JobEndpoints(*ENDPOINT_ARGS)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d15bb26d",
   "metadata": {},
   "source": [
    "#### Create a Quantum Espresso workflow for SCF calculation\n",
    "\n",
    "Below we provide our Quantum Espresso input file via a bash script.\n",
    "\n",
    "Note that we provide the pseudo potential file via a downloadable url. We are working on supporting direct uploading of pseudo potential file from local file system, but it is currently not available. Below are some of the sources to find pseudo potentials:\n",
    "\n",
    "- [Pseudopotentials library at Quantum Espresso](https://www.quantum-espresso.org/pseudopotentials/)\n",
    "- [Standard solid-state pseudopotentials (SSSP) library](https://www.materialscloud.org/discover/sssp/table/efficiency)\n",
    "- [Pseudo dojo library](http://www.pseudo-dojo.org)\n",
    "- [GBRV pseudo potential library](https://www.physics.rutgers.edu/gbrv/)"
   ]
  },
  {
   "cell_type": "code",
   "id": "67bdb4e0-f7b4-4097-b5b9-66c8debaedd3",
   "metadata": {},
   "source": [
    "# user modifiable part\n",
    "script = r\"\"\"#!/bin/bash\n",
    "\n",
    "# switch to the job working directory\n",
    "cd $PBS_O_WORKDIR\n",
    "\n",
    "# ----------------------- QUANTUM ESPRESSO INPUT FILE ------------------------ #\n",
    "cat > pw.in << EOF\n",
    "&CONTROL\n",
    "  calculation = 'scf',\n",
    "  prefix = 'silicon',\n",
    "  outdir = './tmp/'\n",
    "  pseudo_dir = './'\n",
    "/\n",
    "\n",
    "&SYSTEM\n",
    "  ibrav =  2,\n",
    "  celldm(1) = 10.26,\n",
    "  nat =  2,\n",
    "  ntyp = 1,\n",
    "  ecutwfc = 30\n",
    "  nbnd = 8\n",
    "/\n",
    "\n",
    "&ELECTRONS\n",
    "  conv_thr = 1e-8,\n",
    "  mixing_beta = 0.6\n",
    "/\n",
    "\n",
    "ATOMIC_SPECIES\n",
    "  Si 28.086 Si.pz-vbc.UPF\n",
    "\n",
    "ATOMIC_POSITIONS (alat)\n",
    "  Si 0.0 0.0 0.0\n",
    "  Si 0.25 0.25 0.25\n",
    "\n",
    "K_POINTS (automatic)\n",
    "  3 3 3 0 0 0\n",
    "EOF\n",
    "# -------------------------- PSEUDO POTENTIAL FILE --------------------------- #\n",
    "# provide a downloadable link for the pseudo potential file\n",
    "wget https://media.githubusercontent.com/media/exabyte-io/api-examples/dev/examples/assets/Si.pz-vbc.UPF\n",
    "# --------------------------------- RUN JOB ---------------------------------- #\n",
    "# load required module\n",
    "module add espresso/6.3-g-4.8.5-ompi-1.10.0\n",
    "\n",
    "mpirun -np $PBS_NP pw.x -in pw.in | tee pw.out\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8edba851-6207-40ba-beff-ce2b59a1cdfa",
   "metadata": {},
   "source": [
    "# populate workflow from a template\n",
    "import json\n",
    "\n",
    "with open(\"../assets/bash_workflow_template.json\", \"r\") as f:\n",
    "    WORKFLOW_BODY = json.load(f)\n",
    "\n",
    "WORKFLOW_BODY[\"subworkflows\"][0][\"units\"][0][\"input\"][0][\"content\"] = script"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "19037ef9-d5f7-4344-90ea-e7cbf8bbeba0",
   "metadata": {},
   "source": [
    "# create workflow\n",
    "OWNER_ID = os.getenv(\"ORGANIZATION_ID\") or ACCOUNT_ID\n",
    "WORKFLOW_RESP = workflow_endpoints.create(WORKFLOW_BODY, owner_id=OWNER_ID)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf82d280-4a16-4051-b87b-a57e38d71623",
   "metadata": {},
   "source": [
    "### Create and submit job\n",
    "\n",
    "Below user can specify the project name and compute parameters such as `queue`, number of `nodes` and number of processors `ppn` per node. Find more about compute parameters [here](https://docs.mat3ra.com/infrastructure/compute/parameters/)."
   ]
  },
  {
   "cell_type": "code",
   "id": "41d85194-5a2b-4e65-9302-251932d04c11",
   "metadata": {},
   "source": [
    "compute = job_endpoints.get_compute(CLUSTER_NAME, PPN, NODES, QUEUE_NAME, TIME_LIMIT)\n",
    "# job creation payload\n",
    "JOB_BODY = {\n",
    "    \"owner\": {\"_id\": OWNER_ID},\n",
    "    \"name\": \"SCF Calculation\",\n",
    "    \"compute\": compute,\n",
    "    \"workflow\": {\"_id\": WORKFLOW_RESP[\"_id\"]},\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ed28b99-923e-4b30-a0d5-51fe45675c77",
   "metadata": {},
   "source": [
    "# create job\n",
    "JOB_RESP = job_endpoints.create(JOB_BODY)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7dad9ab0-29e7-45a1-832d-364374371c64",
   "metadata": {},
   "source": [
    "# TODO: NOT SUPPORTED YET, upload pseudo potential file\n",
    "# with open('../assets/Si.pz-vbc.UPF', 'r') as f:\n",
    "#     PP_FILE = f.read()\n",
    "#     data = json.dumps({\"files\": PP_FILE})\n",
    "#     FILE_RESP=job_endpoints.insert_output_files(JOB_RESP[\"_id\"], data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aa65092c-a30a-402e-85c2-506746e4664c",
   "metadata": {},
   "source": [
    "# submit job to run\n",
    "job_endpoints.submit(JOB_RESP[\"_id\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5129a629-a46a-4a4c-8de9-98228611aa87",
   "metadata": {},
   "source": [
    "# monitor job and wait for it to be finished\n",
    "wait_for_jobs_to_finish(job_endpoints, [JOB_RESP[\"_id\"]], 30)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0a57e12",
   "metadata": {},
   "source": [
    "#### Get output file, perform post processing, and make plots"
   ]
  },
  {
   "cell_type": "code",
   "id": "87b8fa4b-39cb-4a11-b8da-b07303b9d42c",
   "metadata": {},
   "source": [
    "files = job_endpoints.list_files(JOB_RESP[\"_id\"])\n",
    "for file in files:\n",
    "    if file[\"name\"] == \"pw.out\":\n",
    "        output_file_metadata = file\n",
    "\n",
    "from mat3ra.utils.jupyterlite.url import read_from_url\n",
    "\n",
    "output_file = await read_from_url(output_file_metadata[\"signedUrl\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c160fc04-48c2-40da-b21a-db6706b93dd7",
   "metadata": {},
   "source": [
    "energy = []\n",
    "len_energy = len(\"total energy\")\n",
    "for line in output_file.split(\"\\n\"):\n",
    "    if line.strip().lstrip(\"!\")[:len_energy] == \"total energy\":\n",
    "        energy.append(float(line.split(\"=\")[1].rstrip(\"Ry\")))\n",
    "print(\"Total energy (Ry):\", energy[-1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e89a2984-10d7-4e80-929a-4f818a603d6b",
   "metadata": {},
   "source": [
    "# plot energy with iteration step\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(energy)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Energy (Ry)\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

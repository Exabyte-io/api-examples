{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "n7Si3HU22QxW"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Exabyte-io/api-examples/blob/dev/examples/job/ml-train-model-predict-properties.ipynb\" target=\"_parent\">\n",
    "<img alt=\"Open in Google Colab\" src=\"https://user-images.githubusercontent.com/20477508/128780728-491fea90-9b23-495f-a091-11681150db37.jpeg\" width=\"150\" border=\"0\">\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7m-SyWOK2QxY"
   },
   "source": [
    "# Overview\n",
    "\n",
    "This example demonstrates how to use Mat3ra RESTful API to build a machine learning (ML) model for a set of materials called \"train materials\" and use the model to predict properties of another set called \"target materials\". The general approach can work for multiple properties, we use the Electronic Band Gap in this example.\n",
    "\n",
    "\n",
    "\n",
    "## Steps\n",
    "\n",
    "We follow the below steps:\n",
    "\n",
    "- Import materials from Materials Bank\n",
    "- Calculate band gap for the \"train materials\"\n",
    "- Build ML Train model based on the \"train materials\"\n",
    "- Create and submit a job to predict band gap for the \"target materials\"\n",
    "- Extract band gap for \"target materials\"\n",
    "- Output the results as Pandas dataFrame\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "The explanation below assumes that the reader is familiar with the concepts used in Mat3ra platform and RESTful API. We outline these below and direct the reader to the original sources of information:\n",
    "\n",
    "- [Generating RESTful API authentication parameters](../system/get_authentication_params.ipynb)\n",
    "- [Importing materials from materials bank](../material/get_materials_by_formula.ipynb)\n",
    "- [Creating and submitting jobs](./create_and_submit_job.ipynb)\n",
    "- [Running DFT calculations](./run-simulations-and-extract-properties.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nl8vlnAD2QxZ"
   },
   "source": [
    "# Complete Authorization Form and Initialize Settings\n",
    "\n",
    "This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.\n",
    "\n",
    "If you are running this notebook from Google Colab, Colab takes ~1 min to execute the following cell.\n",
    "\n",
    "ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to [Mat3ra.com's API Endpoints](https://docs.mat3ra.com/rest-api/endpoints/).\n",
    "\n",
    "ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.mat3ra.com/collaboration/organizations/overview/\n",
    "\n",
    "> <span style=\"color: orange\">**NOTE**</span>: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file [settings.json](../../utils/settings.json) if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.mat3ra.com/accounts/ui/preferences/api/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fBhrNDO2QxZ",
    "outputId": "2f059fa9-ccf4-476d-cf20-043ad9cd320d"
   },
   "source": [
    "# @title Authorization Form\n",
    "ACCOUNT_ID = \"ACCOUNT_ID\"  # @param {type:\"string\"}\n",
    "AUTH_TOKEN = \"AUTH_TOKEN\"  # @param {type:\"string\"}\n",
    "ORGANIZATION_ID = \"ORGANIZATION_ID\"  # @param {type:\"string\"}\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "if \"COLAB_JUPYTER_IP\" in os.environ:\n",
    "    os.environ.update(\n",
    "        dict(\n",
    "            ACCOUNT_ID=ACCOUNT_ID,\n",
    "            AUTH_TOKEN=AUTH_TOKEN,\n",
    "            ORGANIZATION_ID=ORGANIZATION_ID,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    !GIT_BRANCH=\"dev\"; export GIT_BRANCH; curl -s \"https://raw.githubusercontent.com/Exabyte-io/api-examples/${GIT_BRANCH}/scripts/env.sh\" | bash\n",
    "\n",
    "if sys.platform == \"emscripten\":\n",
    "    apiConfig = data_from_host.get(\"apiConfig\")\n",
    "    os.environ.update(data_from_host.get(\"environ\", {}))\n",
    "    os.environ.update(\n",
    "        dict(\n",
    "            ACCOUNT_ID=apiConfig.get(\"accountId\"),\n",
    "            AUTH_TOKEN=apiConfig.get(\"authToken\"),\n",
    "            ORGANIZATION_ID=apiConfig.get(\"organizationId\", \"\"),\n",
    "            CLUSTERS=json.dumps(apiConfig.get(\"clusters\", [])),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    import micropip\n",
    "\n",
    "    await micropip.install(\"mat3ra-api-examples\", deps=False)\n",
    "    await micropip.install(\"mat3ra-utils\")\n",
    "    from mat3ra.utils.jupyterlite.packages import install_packages\n",
    "\n",
    "    await install_packages(\"api_examples\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EMKMnghw2Qxa"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xpXAOeAp2Qxa"
   },
   "source": [
    "# Import settings file and utils file\n",
    "from utils.settings import ENDPOINT_ARGS, ACCOUNT_ID\n",
    "from utils.generic import (\n",
    "    dataframe_to_html,\n",
    "    copy_bank_workflow_by_system_name,\n",
    "    wait_for_jobs_to_finish,\n",
    "    get_property_by_subworkflow_and_unit_indicies,\n",
    "    display_JSON,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Import relevant portions of the API client\n",
    "from exabyte_api_client.endpoints.jobs import JobEndpoints\n",
    "from exabyte_api_client.utils.materials import flatten_material\n",
    "from exabyte_api_client.endpoints.projects import ProjectEndpoints\n",
    "from exabyte_api_client.endpoints.materials import MaterialEndpoints\n",
    "from exabyte_api_client.endpoints.workflows import WorkflowEndpoints\n",
    "from exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints\n",
    "from exabyte_api_client.endpoints.bank_materials import BankMaterialEndpoints\n",
    "from exabyte_api_client.endpoints.properties import PropertiesEndpoints"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TNXq-lpw2Qxb"
   },
   "source": [
    "#### Materials\n",
    "\n",
    "Set parameters for the materials to be imported:\n",
    "\n",
    "- **TRAIN_MATERIAL_SI**: 1st material to be used for training the model (\"Si\").\n",
    "- **TRAIN_MATERIAL_GE**: 2nd material to be used for training the model (\"Ge\").\n",
    "- **TARGET_MATERIAL_SIGE**: Material to be used for predicting the properties (\"SiGe\")."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qeZIEenS2Qxb"
   },
   "source": [
    "TRAIN_MATERIAL_SI = \"Si\"\n",
    "TRAIN_MATERIAL_GE = \"Ge\"\n",
    "TARGET_MATERIAL_SIGE = \"SiGe\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zSGV807V2Qxb"
   },
   "source": [
    "#### Jobs\n",
    "\n",
    "Set parameters for the jobs to be ran for the imported materials:\n",
    "\n",
    "- **JOB_NAME_PREFIX**: prefix to be used for the job name with \"{JOB_NAME_PREFIX} {FORMULA}\" convention (e.g.  \"Job Name Prefix - SiGe\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1Z68p_zB2Qxc"
   },
   "source": [
    "JOB_NAME_PREFIX = \"Job Name Prefix\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Compute\n",
    "\n",
    "Setup compute parameters. See [this](https://docs.mat3ra.com/infrastructure/compute/parameters/) for more information about compute parameters.\n",
    "\n",
    "- **CLUSTER_NAME**: The full qualified domain name (FQDN) or alias of the cluster to submit the jobs into.\n",
    "- **PPN**: Number of MPI processes per each node, Defaults to 1.\n",
    "- **NODES**: Number of nodes. Defaults to 1.\n",
    "- **QUEUE_NAME**: The name of queue to submit the jobs into. Defaults to \"D\".\n",
    "- **TIME_LIMIT**: Job walltime. Defaults to \"01:00:00\" (one hour).\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# using the first available cluster and queue in the list\n",
    "cluster_config = next(iter(json.loads(os.getenv(\"CLUSTERS\"))), {})\n",
    "queue_configs = cluster_config.get(\"queues\", [])\n",
    "\n",
    "CLUSTER_NAME = cluster_config.get(\"displayName\", \"cluster-001\")\n",
    "PPN = 1\n",
    "NODES = 1\n",
    "QUEUE_NAME = next(iter(queue_configs), {}).get(\"NAME\", \"D\")\n",
    "TIME_LIMIT = \"01:00:00\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fDGy9Qh52Qxd"
   },
   "source": [
    "### Initialize the endpoints"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EaRDDZ2E2Qxd"
   },
   "source": [
    "job_endpoints = JobEndpoints(*ENDPOINT_ARGS)\n",
    "project_endpoints = ProjectEndpoints(*ENDPOINT_ARGS)\n",
    "material_endpoints = MaterialEndpoints(*ENDPOINT_ARGS)\n",
    "workflow_endpoints = WorkflowEndpoints(*ENDPOINT_ARGS)\n",
    "bank_workflow_endpoints = BankWorkflowEndpoints(*ENDPOINT_ARGS)\n",
    "bank_material_endpoints = BankMaterialEndpoints(*ENDPOINT_ARGS)\n",
    "property_endpoints = PropertiesEndpoints(*ENDPOINT_ARGS)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "uKukWQNL2Qxd"
   },
   "source": [
    "Retrieve the owner and project IDs as they are needed by the endpoints. The default material is used to extract the owner ID. One can extract the owner ID from any other account's [entities](https://docs.mat3ra.com/entities-general/overview/)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g_YTcLgD2Qxd"
   },
   "source": [
    "OWNER_ID = os.getenv(\"ORGANIZATION_ID\") or ACCOUNT_ID\n",
    "owner_id = material_endpoints.list({\"isDefault\": True, \"owner._id\": OWNER_ID})[0][\"owner\"][\"_id\"]\n",
    "project_id = project_endpoints.list({\"isDefault\": True, \"owner._id\": OWNER_ID})[0][\"_id\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "c1aYxrn12Qxe"
   },
   "source": [
    "### Create workflows\n",
    "\n",
    "Copy \"ML: Train Model\" and \"Band Gap\" bank workflows to the account's workflows. We use exabyte bank workflows which are identified by \"systemName\" field. The below can be adjusted to get the bank workflows by ID."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_JUT4f9E2Qxe"
   },
   "source": [
    "band_gap_workflow_id = copy_bank_workflow_by_system_name(bank_workflow_endpoints, \"espresso-band-gap\", OWNER_ID)\n",
    "ml_train_workflow_id = copy_bank_workflow_by_system_name(\n",
    "    bank_workflow_endpoints, \"exabyteml-ml-linear-least-squares-train-model\", OWNER_ID\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aleETRhq2Qxe"
   },
   "source": [
    "### Import materials\n",
    "\n",
    "Import materials from Standata and create them in the account's materials collection."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t1dMm9ke2Qxe"
   },
   "source": [
    "from mat3ra.standata.materials import Materials\n",
    "\n",
    "train_material_json_si = Materials.get_by_name_first_match(TRAIN_MATERIAL_SI)\n",
    "train_material_json_ge = Materials.get_by_name_first_match(TRAIN_MATERIAL_GE)\n",
    "target_material_json_sige = Materials.get_by_name_first_match(TARGET_MATERIAL_SIGE)\n",
    "\n",
    "train_material_id_si = material_endpoints.create(train_material_json_si, OWNER_ID)[\"_id\"]\n",
    "train_material_id_ge = material_endpoints.create(train_material_json_ge, OWNER_ID)[\"_id\"]\n",
    "target_material_id_sige = material_endpoints.create(target_material_json_sige, OWNER_ID)[\"_id\"]\n",
    "\n",
    "train_material_si = material_endpoints.list({\"_id\": train_material_id_si})[0]\n",
    "train_material_ge = material_endpoints.list({\"_id\": train_material_id_ge})[0]\n",
    "target_material_sige = material_endpoints.list({\"_id\": target_material_id_sige})[0]\n",
    "\n",
    "train_materials = [train_material_ge, train_material_si]\n",
    "target_materials = [target_material_sige]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eZTeParO2Qxe"
   },
   "source": [
    "### Calculate Properties for \"train materials\"\n",
    "\n",
    "Create jobs for the \"train materials\"."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gJ7TMXLt2Qxe"
   },
   "source": [
    "compute = job_endpoints.get_compute(CLUSTER_NAME, PPN, NODES, QUEUE_NAME, TIME_LIMIT)\n",
    "jobs = job_endpoints.create_by_ids(\n",
    "    train_materials, band_gap_workflow_id, project_id, JOB_NAME_PREFIX, OWNER_ID, compute\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXJbytcT2Qxe"
   },
   "source": [
    "Submit the jobs for execution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uKLT6vQr2Qxf"
   },
   "source": [
    "for job in jobs:\n",
    "    job_endpoints.submit(job[\"_id\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pUpm3qYO2Qxf"
   },
   "source": [
    "Monitor the jobs and print the status until they are all finished."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIfaCdYQ2Qxf",
    "outputId": "d0a4aa6a-a26b-48ed-b318-39e030ee9ae3"
   },
   "source": [
    "job_ids = [job[\"_id\"] for job in jobs]\n",
    "wait_for_jobs_to_finish(job_endpoints, job_ids)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JSJjMpiw2Qxg"
   },
   "source": [
    "### Build ML Train model\n",
    "\n",
    "Create ML Train job for the train materials."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6LNWH-8f2Qxg"
   },
   "source": [
    "name = \"-\".join((JOB_NAME_PREFIX, \"train\"))\n",
    "material_ids = [m[\"_id\"] for m in train_materials]\n",
    "config = job_endpoints.get_config(material_ids, ml_train_workflow_id, project_id, owner_id, name, compute, True)\n",
    "job = job_endpoints.create(config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_LmJY5Pj2Qxg"
   },
   "source": [
    "Submit the train job for execution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WQMOm3Qk2Qxg"
   },
   "source": [
    "job_endpoints.submit(job[\"_id\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4dub7yC52Qxg"
   },
   "source": [
    "Monitor the job and print the status until it is done."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Q3SU-Es2Qxg",
    "outputId": "dfca0a46-6318-40a9-84a0-5e8925f5958e"
   },
   "source": [
    "wait_for_jobs_to_finish(job_endpoints, [job[\"_id\"]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GjyQbQTQ2Qxh"
   },
   "source": [
    "### Extract ML model as workflow\n",
    "\n",
    "The resulting trained model is extracted from the last unit (train with index 4) of the first job's subworkflow (ML: Train Model with index 0) and is further referred to as \"ML predict workflow\"."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xq_rGr5b2Qxh"
   },
   "source": [
    "ml_predict_workflow = get_property_by_subworkflow_and_unit_indicies(\n",
    "    property_endpoints, \"workflow:ml_predict\", job, 0, 4\n",
    ")[\"data\"]\n",
    "ml_predict_workflow_id = ml_predict_workflow[\"_id\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "VPOx3SxH2Qxh"
   },
   "source": [
    "Print ML predict workflow"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PiUO0kzN2Qxh",
    "outputId": "de75edbe-a3ac-4e1c-c548-9bb2d504b8b8"
   },
   "source": [
    "display_JSON(ml_predict_workflow)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "efI91bkq2Qxh"
   },
   "source": [
    "### Predict property using the model\n",
    "\n",
    "Create ML Predict job for the predict materials."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c-LwLBpY2Qxh"
   },
   "source": [
    "name = \"-\".join((JOB_NAME_PREFIX, \"predict\"))\n",
    "material_ids = [m[\"_id\"] for m in target_materials]\n",
    "config = job_endpoints.get_config(material_ids, ml_predict_workflow_id, project_id, owner_id, name, compute, True)\n",
    "job = job_endpoints.create(config)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UheWoZdU2Qxh"
   },
   "source": [
    "Submit the predict job for execution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C7esLsJC2Qxh"
   },
   "source": [
    "job_endpoints.submit(job[\"_id\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pwMJ2FXR2Qxi"
   },
   "source": [
    "Monitor the job and print the status until its done."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2psMosZs2Qxi",
    "outputId": "3892222c-1f00-4d83-d5b7-83195af3ec5a"
   },
   "source": [
    "wait_for_jobs_to_finish(job_endpoints, [job[\"_id\"]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eSozkejF2Qxi"
   },
   "source": [
    "### Extract predicted properties\n",
    "\n",
    "Predicted properties are extracted from the last unit (score with index 3) of the first job's subworkflow (ml_predict_subworkflow with index 0)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oI_xESvQ2Qxi"
   },
   "source": [
    "predicted_properties = get_property_by_subworkflow_and_unit_indicies(\n",
    "    property_endpoints, \"predicted_properties\", job, 0, 3\n",
    ")[\"data\"][\"values\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xAcQrMz02Qxi"
   },
   "source": [
    "### Flatten results\n",
    "\n",
    "The below for-loop iterates over the results and flatten them to form the final Pandas dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8tInR6TY2Qxi"
   },
   "source": [
    "table = []\n",
    "for exabyte_id, properties in predicted_properties.items():\n",
    "    material = next((m for m in target_materials if m[\"exabyteId\"] == exabyte_id))\n",
    "    band_gaps = next((v for v in properties if v[\"name\"] == \"band_gaps\"))\n",
    "    direct_gap = next((v for v in band_gaps[\"values\"] if v[\"type\"] == \"direct\"))[\"value\"]\n",
    "    indirect_gap = next((v for v in band_gaps[\"values\"] if v[\"type\"] == \"indirect\"))[\"value\"]\n",
    "    table.append(\n",
    "        [material[\"_id\"], material[\"name\"], material[\"formula\"], material[\"exabyteId\"], direct_gap, indirect_gap]\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EiwiUrqZ2Qxi"
   },
   "source": [
    "### Ouput results\n",
    "\n",
    "Create and print the final table as Pandas dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 57
    },
    "id": "aMKkorTl2Qxi",
    "outputId": "e93d96bf-68b6-4e97-baf5-b1fc78a1dacb"
   },
   "source": [
    "headers = [\"ID\", \"NAME\", \"FORMULA\", \"EXABYTE-ID\", \"DIRECT-GAP\", \"INDIRECT-GAP\"]\n",
    "df = pd.DataFrame(data=table, columns=headers)\n",
    "html = dataframe_to_html(df)\n",
    "html"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "name": "ml-train-model-predict-properties.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

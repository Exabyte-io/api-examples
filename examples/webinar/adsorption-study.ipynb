{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eight-centre",
   "metadata": {},
   "source": [
    "# Perform a High-Throughput Adsorption Study\n",
    "\n",
    "This notebook was created to facilitate our April 2021 webinar, which detailed the creation of a simple model of CO adsorption. The video can be found in the following link:\n",
    "\n",
    "https://www.youtube.com/watch?v=wOrqnR8UAbQ\n",
    "\n",
    "The webinar's approach to placing CO molecules in a top-site configuration was based on the approach used in the following work:\n",
    "\n",
    "Dean, J.; Taylor, M. G.; Mpourmpakis, G. Unfolding Adsorption on Metal Nanoparticles: Connecting Stability with catalysis. Sci Adv 2019, 5 (9), eaax5101. DOI: doi.org/10.1126/sciadv.aax5101\n",
    "\n",
    "In this notebook example, we automate the placement of CO molecules to several Cu slabs. We then submit all of these adsorbed states to the cluster as DFT geometry optimization calculations using VASP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3df4a9",
   "metadata": {},
   "source": [
    "# Complete Authorization Form and Initialize Settings\n",
    "\n",
    "The following environment variables need to be set:\n",
    "\n",
    "ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to [Exabyte.io's API Endpoints](https://docs.exabyte.io/rest-api/endpoints/).\n",
    "\n",
    "MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to [Material Project's API](https://materialsproject.org/open)\n",
    "\n",
    "ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.exabyte.io/collaboration/organizations/overview/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92266b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Authorization Form\n",
    "ACCOUNT_ID = \"ACCOUNT_ID\" #@param {type:\"string\"}\n",
    "AUTH_TOKEN = \"AUTH_TOKEN\" #@param {type:\"string\"}\n",
    "MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\" #@param {type:\"string\"}\n",
    "ORGANIZATION_ID  = \"ORGANIZATION_ID\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad3734",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ambient-configuration",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/reag2/exabyte/requirements.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-90fde85bb758>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexabyte_api_examples_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mensure_packages_are_installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mensure_packages_are_installed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexabyte_api_examples_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaterial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_contcar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/exabyte/exabyte-api-examples/exabyte_api_examples_utils/generic.py\u001b[0m in \u001b[0;36mensure_packages_are_installed\u001b[0;34m(notebook_environment, *names)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Install requirements.txt if nothing was passed in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirements_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreqs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreqs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                     \u001b[0;31m# Ignore Jupyterlab, since the user is probably running it already to view the notebooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/reag2/exabyte/requirements.txt'"
     ]
    }
   ],
   "source": [
    "!pip install ase\n",
    "\n",
    "import ase.io\n",
    "import ase.neighborlist\n",
    "import ase.constraints\n",
    "\n",
    "# from exabyte_api_examples_utils.generic import ensure_packages_are_installed\n",
    "# ensure_packages_are_installed()\n",
    "\n",
    "from exabyte_api_examples_utils.material import download_contcar\n",
    "\n",
    "# Import relevant portions of the API client\n",
    "from exabyte_api_client.endpoints.jobs import JobEndpoints\n",
    "from exabyte_api_client.endpoints.projects import ProjectEndpoints\n",
    "from exabyte_api_client.endpoints.materials import MaterialEndpoints\n",
    "from exabyte_api_client.endpoints.workflows import WorkflowEndpoints\n",
    "from exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints\n",
    "\n",
    "from exabyte_api_examples_utils.enum import (\n",
    "    HOST,\n",
    "    PORT,\n",
    "    VERSION,\n",
    "    SECURE,\n",
    ")\n",
    "\n",
    "ENDPOINT_ARGS = [HOST, PORT, ACCOUNT_ID, AUTH_TOKEN, VERSION, SECURE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-badge",
   "metadata": {},
   "source": [
    "# Query the Platform for the Slab\n",
    "\n",
    "Get slab, acquire science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "musical-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_endpoint = JobEndpoints(*ENDPOINT_ARGS)\n",
    "material_endpoint = MaterialEndpoints(*ENDPOINT_ARGS)\n",
    "\n",
    "class JobData():\n",
    "    \"\"\"\n",
    "    Dataclass for the job. Holds references to endpoints, the JSON for the job, along with\n",
    "    other metadata such as the termination and miller index.\n",
    "    \n",
    "    Attributes:\n",
    "        job_endpoint (JobEndpoints): A reference to the job endpoint from the API\n",
    "        material_endpoint (MaterialEndpoints): A reference to the material endpoint from the API\n",
    "        jobId (str): The ID of the job associated with an instance of this class\n",
    "        job_json (dict): JSON data storing the job\n",
    "        termination (str): Termination number for the slab.\n",
    "        miller_index (str): Miller index that was used to cleave the slab.\n",
    "        symbol (str): Atomic symbol for the element comprising the slab.\n",
    "    \"\"\"\n",
    "    def __init__(self, jobId, job_endpoint, material_endpoint):\n",
    "        self.job_endpoint = job_endpoint\n",
    "        self.material_endpoint = material_endpoint\n",
    "        \n",
    "        self.jobId = jobId\n",
    "        \n",
    "        # Run the API call and get the job's name\n",
    "        self.job_json = self.job_endpoint.get(jobId)\n",
    "        self.name = self.job_json[\"name\"]\n",
    "        \n",
    "        # Process the job name\n",
    "        _, _, miller_index, end_string = self.name.split(\"_\")\n",
    "        termination_string, symbol = end_string.split(\" \")\n",
    "        self.termination = int(\"\".join([char if char in string.digits else \"\" for char in termination_string]))\n",
    "        self.miller_index = [int(index) for index in miller_index]\n",
    "        self.symbol = symbol\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return(str(self.name))\n",
    "\n",
    "# Here, we've stored all of our jobs in a specific set. We'll run a Mongo Query to find jobs\n",
    "# that are inside of this set.\n",
    "job_set_id = \"WLBD7M9dZBaNH2mMX\"\n",
    "jobs = [JobData(job[\"_id\"], job_endpoint, material_endpoint) for job in job_endpoint.list({\"inSet\":{\"$elemMatch\":{\"_id\":job_set_id}}})]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-victor",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-father",
   "metadata": {},
   "source": [
    "# Download a Slab from the Platform\n",
    "\n",
    "Now that we have our slab jobs, and a nice object to hold them, let's get them into ASE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-sound",
   "metadata": {},
   "source": [
    "## Get an ASE oject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addressed-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in jobs:\n",
    "    job.filename = f\"{'_'.join(map(str, job.miller_index))}_term{job.termination}.vasp\"\n",
    "    download_contcar(job.jobId, job.job_endpoint, job.filename)\n",
    "    job.structure = ase.io.read(job.filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-sending",
   "metadata": {},
   "source": [
    "## Generate the ASE Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "single-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we've got at least a 5x5 angstrom surface, to help combat lateral interactions in the adsorbates\n",
    "for job in jobs:\n",
    "    a, b, c = job.structure.cell.lengths()\n",
    "    while a < 5 or b < 5:\n",
    "        if a < 5:\n",
    "            job.structure *= [2,1,1]\n",
    "\n",
    "        if b < 5:\n",
    "            job.structure *= [1,2,1]\n",
    "        \n",
    "        a, b, c = job.structure.cell.lengths()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-celebration",
   "metadata": {},
   "source": [
    "## Find the Surface Sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cellular-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_surface_indices(ase_structure, cns):\n",
    "    surface_indices = []\n",
    "    a, b, c = ase_structure.cell.lengths()\n",
    "    for index, (atom, cn) in enumerate(zip(ase_structure, cns)):\n",
    "        # Slabs are centered, so we can easily filter out one half of the atoms\n",
    "        if cn < 12 and atom.position[2] > c/2:\n",
    "            surface_indices.append(index)\n",
    "    return surface_indices\n",
    "\n",
    "for job in jobs:\n",
    "    src, dest = ase.neighborlist.neighbor_list(\"ij\", job.structure, 3)\n",
    "    job.bonds = tuple(zip(src, dest))  \n",
    "    job.cns = np.bincount(src)\n",
    "    job.surface_indices = get_surface_indices(job.structure, job.cns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-victim",
   "metadata": {},
   "source": [
    "# CO Placement\n",
    "\n",
    "Place CO on surface, surface norm is in Z-direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brutal-guide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_co_molecule(job, site):\n",
    "    site_coords = job.structure[site].position\n",
    "    carbon_atom = ase.Atom(\"C\", site_coords + [0, 0, 1.43])\n",
    "    oxygen_atom = ase.Atom(\"O\", site_coords + [0, 0, 2*1.43])\n",
    "    carbon_monoxide = ase.Atoms((carbon_atom, oxygen_atom))\n",
    "    job.adsorption_states.append(job.structure + carbon_monoxide)\n",
    "    \n",
    "for job in jobs:\n",
    "    job.adsorption_states = []\n",
    "    for site in job.surface_indices:\n",
    "        place_co_molecule(job, site)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-progress",
   "metadata": {},
   "source": [
    "And finally, we'll freeze the surface to reduce the computational burden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "australian-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_all_slab_atoms(adsorption_state):\n",
    "    constraint = ase.constraints.FixAtoms(indices = [atom.index for atom in adsorption_state if atom.symbol not in (\"C\", \"O\")])\n",
    "    adsorption_state.set_constraint(constraint)\n",
    "\n",
    "for job in jobs:\n",
    "    for adsorption_state in job.adsorption_states:\n",
    "        fix_all_slab_atoms(adsorption_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-situation",
   "metadata": {},
   "source": [
    "# Adsorption Study\n",
    "\n",
    "Conventionally, the adsorption energy is defined as an energetic comparison between the following two states:\n",
    "1. The two species separated at an infinite distance.\n",
    "2. The two species interacting with one another in some _complex_.\n",
    "\n",
    "At an infinite distance (state 1), there is no interaction between the two species. As a result, the energy of the system is simply the sum of the energies of the two isolated systems. In our case (a molecule which has adsorbed to a slab), the isolated systems are the bare slab and the gas-phase molecule. \n",
    "When the two species are combined (state 2), they interact with one another. The energetic quantification of this interaction (E_ads) is what we seek to determine.\n",
    "\n",
    "Overall, the result is that we must perform three calculations: the gas-phase molecule (E_molecule), the bare slab (E_slab), and the adsorbed state (E_complex). The adsorption energy (E_ads) can then be calculated via the following equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subjective-reserve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "\\begin{align}\n",
       "E_{ads}=E_{complex}-(E_{slab}+E_{molecule})\n",
       "\\end{align}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\n",
    "\\begin{align}\n",
    "E_{ads}=E_{complex}-(E_{slab}+E_{molecule})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "frank-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in jobs:\n",
    "    for index, adsorption_state in enumerate(job.adsorption_states):\n",
    "        job.adsorption_state_names = []\n",
    "        adsorption_state_name = job.filename.replace(\".vasp\", f\"site_{index}\")\n",
    "        job.adsorption_state_names.append(adsorption_state_name) \n",
    "        ase.io.write(adsorption_state_name + \".vasp\", adsorption_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-analyst",
   "metadata": {},
   "source": [
    "## Create the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "metallic-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by finding the slab optimization workflow from the previous webinar\n",
    "bank_workflow_id = \"ByGrAAkeGiopxJdyu\"\n",
    "\n",
    "# Copy over the workflow\n",
    "bank_workflow_endpoint = BankWorkflowEndpoints(*ENDPOINT_ARGS)\n",
    "workflow = bank_workflow_endpoint.copy(bank_workflow_id, account_id=ORGANIZATION_ID)\n",
    "\n",
    "# Copy in our constraints\n",
    "vasp_unit = workflow[\"subworkflows\"][0][\"units\"][0]\n",
    "for input_file in vasp_unit[\"input\"]:\n",
    "    if input_file[\"name\"] == \"POSCAR\":\n",
    "        input_file[\"content\"] = \"{{ input.POSCAR_WITH_CONSTRAINTS }}\"\n",
    "\n",
    "# Set the names to something easy to recognize, and upload\n",
    "workflow_endpoint = WorkflowEndpoints(*ENDPOINT_ARGS)\n",
    "workflow['name'] = 'Constrained Adsorbate_Relaxation'\n",
    "workflow = workflow_endpoint.create(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-estonia",
   "metadata": {},
   "source": [
    "## Upload the Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bridal-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "slab_materials_set = material_endpoint.create_set({\"name\" : \"Webinar_Cu_CO_Slabs\",\n",
    "                                                            \"owner\": {\"_id\": ORGANIZATION_ID}})\n",
    "for job in jobs:\n",
    "    job.slab_ids = []\n",
    "    for jobname in job.adsorption_state_names:\n",
    "        with open(jobname + \".vasp\", \"r\") as inp:\n",
    "            content = \"\".join(inp.readlines())\n",
    "        material_json = material_endpoint.import_from_file(name=jobname, content=content, owner_id=ORGANIZATION_ID)\n",
    "        job.slab_ids.append(material_json[\"_id\"])\n",
    "        material_endpoint.move_to_set(material_json[\"_id\"], \"\", slab_materials_set[\"_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-proportion",
   "metadata": {},
   "source": [
    "## Submit the Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_endpoint = ProjectEndpoints(*ENDPOINT_ARGS)\n",
    "project_id = projects_endpoint.list({\"isDefault\": True,\n",
    "                                             \"owner._id\": ORGANIZATION_ID})[0][\"_id\"]      \n",
    "        \n",
    "for job in jobs:\n",
    "    job.job_ids = []\n",
    "    for jobname, adsorption_state, material_id in zip(job.adsorption_state_names,\n",
    "                                                      job.adsorption_states,\n",
    "                                                      job.slab_ids):\n",
    "                # First, set up the compute parameters\n",
    "        # Add an extra node if there are a lot of atoms in the cell\n",
    "        n_nodes = int(np.rint(len(adsorption_state)))\n",
    "        # Restrict the nodes to at least 1, but no more than 2\n",
    "        n_nodes = min(max(n_nodes, 1), 2)\n",
    "\n",
    "        job_config = {\"ppn\": 16,\n",
    "                      \"queue\": \"OF\",\n",
    "                      \"nodes\": n_nodes,\n",
    "                      \"time_limit\": \"12:00:00\",\n",
    "                      \"cluster\": \"cluster-007\"}\n",
    "        compute = job.job_endpoint.get_compute(**job_config)\n",
    "        \n",
    "        workflow_id = workflow[\"_id\"]\n",
    "        material = material_endpoint.get(material_id)\n",
    "        adsorbate_job = job.job_endpoint.create_by_ids([material],\n",
    "                                                       workflow_id,\n",
    "                                                       project_id,\n",
    "                                                       ORGANIZATION_ID,\n",
    "                                                       jobname,\n",
    "                                                       compute)\n",
    "        job.job_ids.append(adsorbate_job[0][\"_id\"])\n",
    "\n",
    "    for job_id in job.job_ids:\n",
    "        job.job_endpoint.submit(job_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

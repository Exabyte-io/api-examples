{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eLv7xE68GIo"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Exabyte-io/exabyte-api-examples/blob/feature/SOF-4618/examples/job/get-file-from-job.ipynb\" target=\"_blank\">Open in Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1kKqnws8GIq"
   },
   "source": [
    "# Get-File-From-Job\n",
    "\n",
    "This example demonstrates how to use Exabyte RESTful API to check for and acquire files from jobs which have been run. This example assumes that the user is already familiar with the [creation and submission of jobs](create_and_submit_jobs.ipynb) using our API.\n",
    "\n",
    "> <span style=\"color: orange\">**IMPORTANT NOTE**</span>: In order to run this example in full, an active Exabyte.io account is required. Alternatively, Readers may substitute the workflow ID below with another one (an equivalent one for VASP, for example) and adjust extraction of the results (\"Viewing job files\" section). RESTful API credentials shall be updated in [settings](../settings.py).\n",
    "\n",
    "\n",
    "## Steps\n",
    "\n",
    "After working through this notebook, you will be able to:\n",
    "\n",
    "1. Import [the structure of Si](https://materialsproject.org/materials/mp-149/) from Materials Project\n",
    "2. Set up and run a single-point calculation using Quantum Espresso.\n",
    "3. List files currently in the job's directory\n",
    "4. Check metadata for every file (modification date, size, etc)\n",
    "5. Access file contents directly and print them to console\n",
    "6. Download files to your local machine\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "The explanation below assumes that the reader is familiar with the concepts used in Exabyte platform and RESTful API. We outline these below and direct the reader to the original sources of information:\n",
    "\n",
    "- [Generating RESTful API authentication parameters](../system/get_authentication_params.ipynb)\n",
    "- [Importing materials from materials project](../material/import_materials_from_materialsproject.ipynb)\n",
    "- [Creating and submitting jobs](../job/create_and_submit_job.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1oEmy_N8GIr"
   },
   "source": [
    "# Complete Authorization Form and Initialize Settings\n",
    "\n",
    "This will also determine environment and set all environment variables. We determine if we are using Jupyter Notebooks or Google Colab to run this tutorial.\n",
    "\n",
    "ACCOUNT_ID and AUTH_TOKEN - Authentication parameters needed for when making requests to [Exabyte.io's API Endpoints](https://docs.exabyte.io/rest-api/endpoints/).\n",
    "\n",
    "MATERIALS_PROJECT_API_KEY - Authentication parameter needed for when making requests to [Material Project's API](https://materialsproject.org/open)\n",
    "\n",
    "ORGANIZATION_ID - Authentication parameter needed for when working with collaborative accounts https://docs.exabyte.io/collaboration/organizations/overview/\n",
    "\n",
    "> <span style=\"color: orange\">**NOTE**</span>: If you are running this notebook from Jupyter, the variables ACCOUNT_ID, AUTH_TOKEN, MATERIALS_PROJECT_API_KEY, and ORGANIZATION_ID should be set in the file [settings.json](../settings.json) if you need to use these variables. To obtain API token parameters, please see the following link to the documentation explaining how to get them: https://docs.exabyte.io/accounts/ui/preferences/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nXDYU_oP8GIr",
    "outputId": "aee909b7-1a48-43c2-81b7-3659e0fc9c79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'exabyte-api-examples'...\n",
      "remote: Enumerating objects: 2455, done.\u001b[K\n",
      "remote: Counting objects: 100% (421/421), done.\u001b[K\n",
      "remote: Compressing objects: 100% (203/203), done.\u001b[K\n",
      "remote: Total 2455 (delta 325), reused 302 (delta 218), pack-reused 2034\u001b[K\n",
      "Receiving objects: 100% (2455/2455), 34.86 MiB | 24.45 MiB/s, done.\n",
      "Resolving deltas: 100% (1387/1387), done.\n"
     ]
    }
   ],
   "source": [
    "#@title Authorization Form\n",
    "ACCOUNT_ID = \"ACCOUNT_ID\" #@param {type:\"string\"}\n",
    "AUTH_TOKEN = \"AUTH_TOKEN\" #@param {type:\"string\"}\n",
    "MATERIALS_PROJECT_API_KEY = \"MATERIALS_PROJECT_API_KEY\" #@param {type:\"string\"}\n",
    "ORGANIZATION_ID  = \"ORGANIZATION_ID\" #@param {type:\"string\"}\n",
    "import os, glob, sys, importlib, urllib.request\n",
    "\n",
    "# The below execution sets up runtime using code stored remotely in a url\n",
    "exec(urllib.request.urlopen('https://raw.githubusercontent.com/Exabyte-io/exabyte-api-examples/dev/examples/utils/initialize_settings.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Z9Cr0_M8GIs"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rG9HfjnR8GIs"
   },
   "outputs": [],
   "source": [
    "# Import settings file and utils file\n",
    "import settings; importlib.reload(settings)\n",
    "from settings import ENDPOINT_ARGS, ACCOUNT_ID, MATERIALS_PROJECT_API_KEY\n",
    "from utils.generic import wait_for_jobs_to_finish, get_property_by_subworkow_and_unit_indicies, dataframe_to_html, display_JSON\n",
    "\n",
    "# Relevant functions from the API client\n",
    "from exabyte_api_client.endpoints.jobs import JobEndpoints\n",
    "from exabyte_api_client.endpoints.projects import ProjectEndpoints\n",
    "from exabyte_api_client.endpoints.materials import MaterialEndpoints\n",
    "from exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints\n",
    "from exabyte_api_client.endpoints.raw_properties import RawPropertiesEndpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zKrDX3q8GIt"
   },
   "source": [
    "### Create and submit the job\n",
    "\n",
    "For this job, we'll use the workflow located [here](https://platform.exabyte.io/analytics/workflows/84DAjE9YyTFndx6z3).\n",
    "\n",
    "This workflow is a single-point total energy calculation using Density-Functional Energy as-implemented in Quantum Espresso version 5.4.0.\n",
    "\n",
    "The PBE functional is used in conjunction with an ultrasoft pseudopotential and a planewave basis set.\n",
    "\n",
    "The material we will investigate is elemental [Silicon](https://materialsproject.org/materials/mp-149/), as-is from Materials Project.\n",
    "\n",
    "> <span style=\"color: orange\">Note</span>: This cell uses our API to copy the unit cell of silicon from Materials Project into your account. It then copies a workflow to get the total energy of a system using Quantum Espresso to your account. Finally, a job is created using the Quantum Espresso workflow for the silicon unit cell, and the job is submitted to the cluster. For more information, please refer to our [run-simulation-and-extract-properties](./run-simulations-and-extract-properties.ipynb) notebook, located in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "le9f28c08GIt",
    "outputId": "27e9b94f-29dd-4742-9448-2e1bce79cb15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for jobs to finish, poll interval: 10 sec\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:54:52 |                1 |             0 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:55:02 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:55:13 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:55:24 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:55:34 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:55:45 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:55:55 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:56:06 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:56:17 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:56:27 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:56:38 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:56:49 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:56:59 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:57:10 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:57:20 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:57:31 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:57:42 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:57:52 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:58:03 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:58:13 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:58:24 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:58:35 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:58:45 |                0 |             1 |               0 |              0 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n",
      "|        TIME         |   SUBMITTED-JOBS |   ACTIVE-JOBS |   FINISHED-JOBS |   ERRORED-JOBS |\n",
      "+=====================+==================+===============+=================+================+\n",
      "| 2021-07-12-13:58:56 |                0 |             0 |               0 |              1 |\n",
      "+---------------------+------------------+---------------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "# Get some account information\n",
    "project_endpoints = ProjectEndpoints(*ENDPOINT_ARGS)\n",
    "project_metadata = project_endpoints.list({\"isDefault\": True, \"owner._id\": ACCOUNT_ID})[0]\n",
    "project_id = project_metadata['_id']\n",
    "owner_id = project_metadata['owner']['_id']\n",
    "\n",
    "# Get a workflow for the job from the bank, and copy it to our account\n",
    "bank_workflow_endpoints = BankWorkflowEndpoints(*ENDPOINT_ARGS)\n",
    "BANK_WORKFLOW_ID = \"84DAjE9YyTFndx6z3\"\n",
    "workflow_id = bank_workflow_endpoints.copy(BANK_WORKFLOW_ID, owner_id)[\"_id\"]\n",
    "\n",
    "# Get materials for the job\n",
    "material_endpoints = MaterialEndpoints(*ENDPOINT_ARGS)\n",
    "material_project_id = [\"mp-149\"] # The importer expects a list\n",
    "materials = material_endpoints.import_from_materialsproject(MATERIALS_PROJECT_API_KEY, material_project_id, owner_id)\n",
    "\n",
    "# Create the job\n",
    "job_endpoints = JobEndpoints(*ENDPOINT_ARGS)\n",
    "job = job_endpoints.create_by_ids(materials = materials,\n",
    "                                   workflow_id = workflow_id,\n",
    "                                   project_id = project_id,\n",
    "                                   owner_id = owner_id,\n",
    "                                   prefix = \"Test_Job_Output\")[0]\n",
    "\n",
    "# Submit the job\n",
    "job_endpoints.submit(job['_id'])\n",
    "wait_for_jobs_to_finish(job_endpoints, [job['_id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kiCDWnVP8GIu"
   },
   "source": [
    "Monitor the jobs and print the status until they are all finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XygP7P1m8GIv"
   },
   "source": [
    "## Viewing job files\n",
    "### Retreive a list of job files\n",
    "\n",
    "Here, we'll get a list of all files that belong to the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yijRe7qp8GIv",
    "outputId": "19b147fc-736e-41f0-bd0f-6f69e77b0adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/.exabyte/checkpoint\n",
      "/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/.exabyte/job.rms\n",
      "/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/.exabyte/machines-80482.master-production-20160630-cluster-001.exabyte.io\n",
      "/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/.exabyte/rupy.log\n",
      "/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/6zP7nscCSArCXbWMC.json\n",
      "/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/job.log\n",
      "/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/pseudo/si_pbe_gbrv_1.0.upf\n",
      "/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/pw_scf.in\n",
      "/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/pw_scf.out\n"
     ]
    }
   ],
   "source": [
    "files = job_endpoints.list_files(job['_id'])\n",
    "paths = [file['key'] for file in files]\n",
    "for path in paths:\n",
    "    if 'outdir' not in path:\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exnQTPwF8GIv"
   },
   "source": [
    "### Get metadata for the Output File\n",
    "The .out file is where Quantum Espresso shows its work and prints its results, so you most likely will want to view this files. Let's print out some of its metadata.\n",
    "\n",
    "You'll find that we get a lot of data describing the file and its providence. Brief explanations of each entry are:\n",
    "- Key - Path to the file on the cluster\n",
    "- size - Size of the file, in bytes.\n",
    "- Bucket - The name of the cluster which ran the job.\n",
    "- Region - Which server region was used to run the job.\n",
    "- Provider - The cluster provider for the compute resources (in our case, we used AWS).\n",
    "- lastModified - Unix timestamp representing when the file was last modified.\n",
    "- name - The filename.\n",
    "- signedUrl - This is a link which can be used to download the file for a short amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2dq0A1e8GIw",
    "outputId": "7b4f8c36-6342-46fa-d02e-0825b44e6c64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"key\": \"/cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/pw_scf.out\",\n",
      "    \"size\": 10553,\n",
      "    \"bucket\": \"production-20160630-cluster-001\",\n",
      "    \"region\": \"us-east-1\",\n",
      "    \"provider\": \"aws\",\n",
      "    \"lastModified\": 1626098186,\n",
      "    \"name\": \"pw_scf.out\",\n",
      "    \"signedUrl\": \"https://production-20160630-cluster-001.s3.amazonaws.com//cluster-001-home/bsmith/data/bsmith-default/test-job-output-si-7-6zP7nscCSArCXbWMC/pw_scf.out?AWSAccessKeyId=AKIAJVUKZ43HBUUYOVFQ&Expires=1626099269&Signature=7E4e3lXd%2BHdhl0YNAKp1TJ7k%2FpE%3D\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    if file['name'] == 'pw_scf.out':\n",
    "        output_file_metadata = file\n",
    "display_JSON(output_file_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwC7wQZR8GIw"
   },
   "source": [
    "### Display file contents to console\n",
    "\n",
    "The signedUrl gives us a place to access the file and download it. Let's read it into memory, and print out the last few lines of our job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpdOMuDT8GIw",
    "outputId": "e4e2e6b1-8431-439a-8606-ae500534e601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Number of k-points >= 100: set verbosity='high' to print the bands.\n",
      "\n",
      "     the Fermi energy is     6.3221 ev\n",
      "\n",
      "!    total energy              =     -19.19341539 Ry\n",
      "     Harris-Foulkes estimate   =     -19.19341500 Ry\n",
      "     estimated scf accuracy    <       0.00000029 Ry\n",
      "\n",
      "     The total energy is the sum of the following terms:\n",
      "\n",
      "     one-electron contribution =       4.94851199 Ry\n",
      "     hartree contribution      =       1.13424409 Ry\n",
      "     xc contribution           =      -8.59619469 Ry\n",
      "     ewald contribution        =     -16.67997678 Ry\n",
      "     smearing contrib. (-TS)   =      -0.00000000 Ry\n",
      "\n",
      "     convergence has been achieved in   5 iterations\n",
      "\n",
      "     Forces acting on atoms (Ry/au):\n",
      "\n",
      "     atom    1 type  1   force =     0.00000019    0.00000022    0.00000000\n",
      "     atom    2 type  1   force =    -0.00000019   -0.00000022    0.00000000\n",
      "\n",
      "     Total force =     0.000000     Total SCF correction =     0.000000\n",
      "     SCF correction compared to forces is large: reduce conv_thr to get better values\n",
      "\n",
      "\n",
      "     entering subroutine stress ...\n",
      "\n",
      "          total   stress  (Ry/bohr**3)                   (kbar)     P=   -0.55\n",
      "  -0.00000372   0.00000000   0.00000000         -0.55      0.00      0.00\n",
      "   0.00000000  -0.00000371   0.00000000          0.00     -0.55      0.00\n",
      "   0.00000000   0.00000000  -0.00000371          0.00      0.00     -0.55\n",
      "\n",
      "\n",
      "     Writing output data file __prefix__.save\n",
      " \n",
      "     init_run     :      2.68s CPU      2.75s WALL (       1 calls)\n",
      "     electrons    :     52.57s CPU     53.39s WALL (       1 calls)\n",
      "     forces       :      0.40s CPU      0.43s WALL (       1 calls)\n",
      "     stress       :      1.51s CPU      1.58s WALL (       1 calls)\n",
      "\n",
      "     Called by init_run:\n",
      "     wfcinit      :      2.42s CPU      2.46s WALL (       1 calls)\n",
      "     potinit      :      0.03s CPU      0.04s WALL (       1 calls)\n",
      "\n",
      "     Called by electrons:\n",
      "     c_bands      :     44.66s CPU     45.18s WALL (       6 calls)\n",
      "     sum_band     :      7.62s CPU      7.82s WALL (       6 calls)\n",
      "     v_of_rho     :      0.15s CPU      0.16s WALL (       6 calls)\n",
      "     newd         :      0.16s CPU      0.28s WALL (       6 calls)\n",
      "     mix_rho      :      0.01s CPU      0.01s WALL (       6 calls)\n",
      "\n",
      "     Called by c_bands:\n",
      "     init_us_2    :      1.10s CPU      1.12s WALL (    4230 calls)\n",
      "     cegterg      :     39.81s CPU     40.26s WALL (    1692 calls)\n",
      "\n",
      "     Called by sum_band:\n",
      "     sum_band:bec :      0.01s CPU      0.01s WALL (    1692 calls)\n",
      "     addusdens    :      0.21s CPU      0.33s WALL (       6 calls)\n",
      "\n",
      "     Called by *egterg:\n",
      "     h_psi        :     38.83s CPU     39.27s WALL (    6240 calls)\n",
      "     s_psi        :      0.61s CPU      0.62s WALL (    6240 calls)\n",
      "     g_psi        :      0.19s CPU      0.19s WALL (    4266 calls)\n",
      "     cdiaghg      :      0.68s CPU      0.69s WALL (    5676 calls)\n",
      "\n",
      "     Called by h_psi:\n",
      "     add_vuspsi   :      0.61s CPU      0.62s WALL (    6240 calls)\n",
      "\n",
      "     General routines\n",
      "     calbec       :      0.98s CPU      0.99s WALL (    9342 calls)\n",
      "     fft          :      0.13s CPU      0.13s WALL (     121 calls)\n",
      "     ffts         :      0.01s CPU      0.01s WALL (      12 calls)\n",
      "     fftw         :     40.39s CPU     40.84s WALL (   90708 calls)\n",
      "     interpolate  :      0.02s CPU      0.02s WALL (      12 calls)\n",
      " \n",
      "     Parallel routines\n",
      "     fft_scatter  :      1.94s CPU      1.96s WALL (   90841 calls)\n",
      " \n",
      "     PWSCF        :  0m57.73s CPU     1m 7.92s WALL\n",
      "\n",
      " \n",
      "   This run was terminated on:  13:56: 2  12Jul2021            \n",
      "\n",
      "=------------------------------------------------------------------------------=\n",
      "   JOB DONE.\n",
      "=------------------------------------------------------------------------------=\n",
      "\n"
     ]
    }
   ],
   "source": [
    "server_response = urllib.request.urlopen(output_file_metadata['signedUrl'])\n",
    "output_file_bytes = server_response.read()\n",
    "\n",
    "# The server returns us a bytes-string. That's useful for things like binaries or other non-human-readable data, but this should be decoded if we're planning to write to console.\n",
    "# Because this is a human-readable text file, we'll decode it to UTF-8.\n",
    "output_file = output_file_bytes.decode(encoding=\"UTF-8\")\n",
    "\n",
    "# Tail the last 90 lines\n",
    "lines = output_file.split(\"\\n\")\n",
    "for line in lines[-90:]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z7VqM3K8GIx"
   },
   "source": [
    "### Save the input file and output file to disk.\n",
    "\n",
    "Now that we've verified the job is done, let's go ahead and save it and its input to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "osy2JKpB8GIx"
   },
   "outputs": [],
   "source": [
    "# We've already got an output file, so et's grab the input file we sent to Quantum Espresso\n",
    "for file in files:\n",
    "    if 'pw_scf.in' == file['name']:\n",
    "        input_file_metadata = file     \n",
    "server_response = urllib.request.urlopen(input_file_metadata['signedUrl'])\n",
    "input_file_bytes = server_response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "COPinBrO8GIx"
   },
   "outputs": [],
   "source": [
    "# Let's write the input file to disk. Note that we get files as a bytes string from the server, which is convenient for binaries, images, and other non-human-readable data.\n",
    "# Although we could decode before writing to disk, we can just write it directly with the \"wb\" (write bytes) file mode.\n",
    "with open(input_file_metadata['name'], 'wb') as file_descriptor:\n",
    "    file_descriptor.write(input_file_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rzDcWyrL8GIx"
   },
   "outputs": [],
   "source": [
    "# Now, let's write our output file to the disk. Note that because we already decoded it, we can just use the 'w' file mode.\n",
    "with open(output_file_metadata['name'], 'w') as file_descriptor:\n",
    "    file_descriptor.write(output_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "get-file-from-job.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nasty-symphony",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This example has been created as part of our Advanced Topics Webinar, scheduled for March 26, 2021. This webinar focused on the high-throughput screening of surfaces using Exabyte.\n",
    "\n",
    "In this notebook, we investigate the stability of a variety of different surfaces of Cu. After the surface energies are all automatically calculated, we finish by creating a Wulff Construction of Cu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interior-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import ase.io\n",
    "import ase.cluster\n",
    "\n",
    "import pymatgen.ext.matproj\n",
    "import pymatgen.io.ase\n",
    "import pymatgen.symmetry.analyzer\n",
    "import numpy as np\n",
    "\n",
    "# Import settings file and utils\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from utils.generic import ensure_packages_are_installed, save_files\n",
    "ensure_packages_are_installed()\n",
    "from utils.material import get_all_slabs_and_terms\n",
    "from utils.material import get_vasp_total_energy, get_slab_area, get_surface_energy\n",
    "from settings import MATERIALS_PROJECT_API_KEY, ENDPOINT_ARGS, ORGANIZATION_ID\n",
    "\n",
    "# Import relevant portions of the API client\n",
    "from exabyte_api_client.endpoints.jobs import JobEndpoints\n",
    "from exabyte_api_client.endpoints.projects import ProjectEndpoints\n",
    "from exabyte_api_client.endpoints.materials import MaterialEndpoints\n",
    "from exabyte_api_client.endpoints.workflows import WorkflowEndpoints\n",
    "from exabyte_api_client.endpoints.bank_workflows import BankWorkflowEndpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-egypt",
   "metadata": {},
   "source": [
    "# Get Unit Cells\n",
    "\n",
    "We begin by finding the following unit cell:\n",
    "- Cu, whose conventional unit cell is taken directly from Materials Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "final-prerequisite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This database version has changed from the database last accessed (2021_02_08).\n",
      "Please see release notes on materialsproject.org for information about what has changed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mat3ra/PycharmProjects/exabyte-api-examples/.env/lib/python3.8/site-packages/pymatgen/ext/matproj.py:559: FutureWarning: __init__ is deprecated\n",
      "MaterialsProjectCompatibility will be updated with new correction classes as well as new values of corrections and uncertainties in 2020\n",
      "  entries = MaterialsProjectCompatibility().process_entries(entries)\n"
     ]
    }
   ],
   "source": [
    "def get_best_structure_by_formula(formula: str) -> pymatgen.ext.matproj.ComputedStructureEntry:\n",
    "    # Create the Materials Project API object\n",
    "    materials_project_api = pymatgen.ext.matproj.MPRester(MATERIALS_PROJECT_API_KEY)\n",
    "\n",
    "    # Query for possible cells of Cu\n",
    "    cu_structs = materials_project_api.get_entries(formula,\n",
    "                                                   conventional_unit_cell=True,\n",
    "                                                   sort_by_e_above_hull=True,\n",
    "                                                   inc_structure=\"initial\")\n",
    "    best_cu_struct = cu_structs[0]\n",
    "    return best_cu_struct\n",
    "\n",
    "# Get Cu from Materials Project\n",
    "cu_pymatgen = get_best_structure_by_formula(\"Cu\").structure\n",
    "cu_ase = pymatgen.io.ase.AseAtomsAdaptor.get_atoms(cu_pymatgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-forest",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, upload the unit cell to the Exabyte.IO Platform.\n",
    "\n",
    "Note that this is in contrast to the way we import directly from Materials Project via IDs as in `materials/import_from_materials_project.ipynb` or in `material/api_interoperability_showcase.ipynb`. This is done deliberately to demonstrate the flexibility offered by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "rapid-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our Materials Endpoint\n",
    "exabyte_materials_endpoint = MaterialEndpoints(*ENDPOINT_ARGS)\n",
    "\n",
    "# Uplad Cu\n",
    "cu_poscar_filename = \"cu.vasp\"\n",
    "ase.io.write(cu_poscar_filename, cu_ase)\n",
    "with open(cu_poscar_filename, \"r\") as inp:\n",
    "    content = inp.read()\n",
    "    cu_cell_material = exabyte_materials_endpoint.import_from_file(name=\"Copper_Unit_Cell\", \n",
    "                                                                   content=content,\n",
    "                                                                   owner_id=ORGANIZATION_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-edinburgh",
   "metadata": {},
   "source": [
    "# Optimize the Unit Cell\n",
    "\n",
    "We begin by specifying our INCAR file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "hungarian-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCAR based on https://www.nature.com/articles/sdata201680#Sec2\n",
    "incar_content = [\"EDIFF = 1e-6\",\n",
    "                 \"EDIFFG = -0.01\",\n",
    "                 \"ISMEAR = 2\",\n",
    "                 \"IBRION = 2\",\n",
    "                 \"ISIF = 3\",\n",
    "                 \"KPAR = 4\",\n",
    "                 \"NSW = 300\",\n",
    "                 \"ENCUT = 400\"]\n",
    "\n",
    "kpoints_content = [\"Automatic mesh\",\n",
    "                   \"0\",\n",
    "                   \"Gamma\",\n",
    "                   \"8 8 8\",\n",
    "                   \"0 0 0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-cancellation",
   "metadata": {},
   "source": [
    "Create a workflow based on the Variable-cell Relaxation workflow available [here](https://platform.exabyte.io/analytics/workflows/NAdKjws8qieKWeYnL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "uniform-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by finding a unit cell optimization workflow on the Exabyte platform. The bank workflow ID can be found in the bank workflows URL\n",
    "bank_workflow_id = \"NAdKjws8qieKWeYnL\"\n",
    "\n",
    "# Set up our Bank Workflow endpoint and copy over the workflow\n",
    "exabyte_bank_workflows_endpoint = BankWorkflowEndpoints(*ENDPOINT_ARGS)\n",
    "cu_workflow = exabyte_bank_workflows_endpoint.copy(bank_workflow_id,\n",
    "                                                   account_id = ORGANIZATION_ID)\n",
    "\n",
    "# Update the workflow with our custom INCAR file\n",
    "vasp_unit = cu_workflow[\"subworkflows\"][0][\"units\"][0]\n",
    "for input_file in vasp_unit[\"input\"]:\n",
    "    if input_file[\"name\"] == \"INCAR\":\n",
    "        input_file['content'] = \"\\n\".join(incar_content)\n",
    "    elif input_file[\"name\"] == \"KPOINTS\":\n",
    "        input_file['content'] = \"\\n\".join(kpoints_content)\n",
    "\n",
    "# Set the names to something easy to recognize, and upload\n",
    "cu_workflow['name'] = 'Copper_Cell_Relax'\n",
    "exabyte_workflows_endpoint = WorkflowEndpoints(*ENDPOINT_ARGS)\n",
    "cu_cellopt_workflow = exabyte_workflows_endpoint.create(cu_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-squad",
   "metadata": {},
   "source": [
    "Create the job for the unit cell optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "previous-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default projectID for the organization account (this can be substituted with a userID)\n",
    "exabyte_projects_endpoint = ProjectEndpoints(*ENDPOINT_ARGS)\n",
    "project_id = exabyte_projects_endpoint.list({\"isDefault\": True,\n",
    "                                             \"owner._id\": ORGANIZATION_ID})[0][\"_id\"]\n",
    "\n",
    "# Create the compute configuration for the jobs on Azure\n",
    "exabyte_jobs_endpoint = JobEndpoints(*ENDPOINT_ARGS)\n",
    "job_config = {\"ppn\": 4,\n",
    "              \"queue\": \"D\",\n",
    "              \"nodes\": 1,\n",
    "              \"time_limit\": \"00:10:00\",\n",
    "              \"cluster\": \"cluster-001\"}\n",
    "compute = exabyte_jobs_endpoint.get_compute(**job_config)\n",
    "\n",
    "# Create the Cu job\n",
    "cu_job = exabyte_jobs_endpoint.create_by_ids([cu_cell_material],\n",
    "                                             cu_cellopt_workflow[\"_id\"],\n",
    "                                             project_id,\n",
    "                                             ORGANIZATION_ID,\n",
    "                                             \"cu_cellopt\",\n",
    "                                             compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-arctic",
   "metadata": {},
   "source": [
    "Finally, submit the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "virgin-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "exabyte_jobs_endpoint.submit(cu_job[0][\"_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-kitty",
   "metadata": {},
   "source": [
    "# Generate the Slabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-korean",
   "metadata": {
    "tags": []
   },
   "source": [
    "We begin by extracting the relaxed unit cell from the job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "gorgeous-afternoon",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a list of files for each\n",
    "cu_job_id = cu_job[0][\"_id\"]\n",
    "\n",
    "save_files(cu_job_id, exabyte_jobs_endpoint, \"CONTCAR\", \"cu_relaxed.vasp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-monitoring",
   "metadata": {},
   "source": [
    "The below code uses Pymatgen to find all unique planes in a crystal. It then generates slabs with every possible termination in that plane. Finally, asymmetric slabs are filtered out, and the slabs are saved to a dictionary. The dictionary's format is: `{miller-index: {termination: {\"slab\": slab} }`. Note that here, to take advantage of several convenient functions in ASE, we have the function output ASE Atoms objects instead of PyMatGen objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "crude-pastor",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cu_relaxed_pymatgen = pymatgen.core.structure.Structure.from_file(\"cu_relaxed.vasp\")\n",
    "\n",
    "# It is important to standardize the cell before cleaving planes\n",
    "standardizer = pymatgen.symmetry.analyzer.SpacegroupAnalyzer(cu_relaxed_pymatgen)\n",
    "cu_relaxed_pymatgen = standardizer.get_conventional_standard_structure()\n",
    "\n",
    "cu_slabs = get_all_slabs_and_terms(cu_relaxed_pymatgen, thickness = 15, is_by_layers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-fortune",
   "metadata": {},
   "source": [
    "# Write Slabs to POSCARs\n",
    "\n",
    "A critical part of any VASP calculation is the actual POSCAR file - the file that contains the atomic coordinates.\n",
    "In this section, we take the slabs we generated above, and prepare them for the VASP calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "champion-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the vacuum size we want to have (for easy adjustment by future users)\n",
    "vacuum_size = 15\n",
    "for miller_index, term_dict in cu_slabs.items():\n",
    "    for term, surface in term_dict.items():\n",
    "        slab = surface[\"slab\"]\n",
    "        # Center the slab's coordinates and adjust the vacuum to vacuum_size\n",
    "        # Note that the \"vacuum\" argument refers to the amount of vacuum on either side - so we divide by 2\n",
    "        slab.center(vacuum=vacuum_size/2, axis=2)\n",
    "\n",
    "        # Write the slab to a file\n",
    "        formula = slab.get_chemical_formula(empirical=True)\n",
    "        filename = f\"{formula}_{miller_index}_term{term}.vasp\"\n",
    "        ase.io.write(filename, slab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-mainland",
   "metadata": {},
   "source": [
    "# Upload POSCARS to Exabyte.io\n",
    "\n",
    "Now that we have a set of prepared POSCARs, we can upload them to our user account on Exabyte. Let's create a couple material sets to hold these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "colonial-disorder",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cu_materials_set = exabyte_materials_endpoint.create_set({\"name\" : \"Webinar_Cu_Wulff_Slabs\",\n",
    "                                                         \"owner\": {\"_id\": ORGANIZATION_ID}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-gallery",
   "metadata": {},
   "source": [
    "We want to keep track of material IDs as we go along, so we'll add this key to our Surface dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "transsexual-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "for miller_index, term_dict in cu_slabs.items():\n",
    "    for term, surface in term_dict.items():\n",
    "        slab = surface[\"slab\"]\n",
    "\n",
    "        # Get the filename we generated above\n",
    "        formula = slab.get_chemical_formula(empirical=True)\n",
    "        material_name = f\"{formula}_{miller_index}_term{term}\"\n",
    "        filename = f\"{material_name}.vasp\"\n",
    "\n",
    "        # Import the material to Exabyte, and place it in the correct material set\n",
    "        with open(filename, \"r\") as inp:\n",
    "            content = inp.read()\n",
    "        material_json = exabyte_materials_endpoint.import_from_file(name=material_name,\n",
    "                                                                    content=content,\n",
    "                                                                    owner_id=ORGANIZATION_ID)\n",
    "        exabyte_materials_endpoint.move_to_set(material_json[\"_id\"], \"\", cu_materials_set[\"_id\"])\n",
    "\n",
    "        # Adjust our dictionary to keep track of the Material ID\n",
    "        surface[\"material_id\"] = material_json[\"_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-italian",
   "metadata": {},
   "source": [
    "# Optimize the Cu Slabs\n",
    "\n",
    "Now it is time to optimize the Cu slabs. We begin by specifying our INCAR file. It is largely the same as the previous INCAR, except with ISIF set to 2, to avoid changing the cell dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "built-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "incar_content = [\"EDIFF = 1e-6\",\n",
    "                 \"EDIFFG = -0.01\",\n",
    "                 \"ISMEAR = 2\",\n",
    "                 \"IBRION = 2\",\n",
    "                 \"ISIF = 2\",\n",
    "                 \"KPAR = 4\",\n",
    "                 \"NSW = 300\",\n",
    "                 \"ENCUT = 400\"]\n",
    "kpoints_content = [\"Automatic mesh\",\n",
    "                   \"0\",\n",
    "                   \"Gamma\",\n",
    "                   \"8 8 1\",\n",
    "                   \"0 0 0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-joint",
   "metadata": {},
   "source": [
    "Next, we'll create the surface relaxation jobs. We start by cloning in a fixed cell relaxation workflow and adjusting it to suit our purposes.\n",
    "The workflow we will choose can be found [here](https://platform.exabyte.io/analytics/workflows/rTEtXntXo3ScGhi7q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ethical-wisdom",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start by finding a fixed cell optimization workflow on the Exabyte platform.\n",
    "bank_workflow_id = \"rTEtXntXo3ScGhi7q\"\n",
    "\n",
    "# Copy over the workflow\n",
    "workflow = exabyte_bank_workflows_endpoint.copy(bank_workflow_id,\n",
    "                                                account_id=ORGANIZATION_ID)\n",
    "\n",
    "# Add in our INCAR\n",
    "vasp_unit = workflow[\"subworkflows\"][0][\"units\"][0]\n",
    "for input_file in vasp_unit[\"input\"]:\n",
    "    if input_file[\"name\"] == \"INCAR\":\n",
    "        input_file[\"content\"] = \"\\n\".join(incar_content)\n",
    "    elif input_file[\"name\"] == \"KPOINTS\":\n",
    "        input_file[\"content\"] = \"\\n\".join(kpoints_content)\n",
    "\n",
    "# Set the names to something easy to recognize, and upload\n",
    "workflow['name'] = 'Copper_Slab_Relax'\n",
    "workflow = exabyte_workflows_endpoint.create(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-family",
   "metadata": {},
   "source": [
    "Next, create the slab relaxation jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "documentary-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "for miller_index, term_dict in cu_slabs.items():\n",
    "    for term, surface in term_dict.items():\n",
    "        # First, set up the compute parameters\n",
    "        # Add an extra node if there are a lot of atoms in the cell\n",
    "        n_nodes = int(np.rint(len(surface[\"slab\"])/16))\n",
    "        # Restrict the nodes to at least 1, but no more than 2\n",
    "        n_nodes = min(max(n_nodes, 1), 2)\n",
    "\n",
    "        job_config = {\"ppn\": 16,\n",
    "                      \"queue\": \"OF\",\n",
    "                      \"nodes\": n_nodes,\n",
    "                      \"time_limit\": \"12:00:00\",\n",
    "                      \"cluster\": \"cluster-007\"}\n",
    "        compute = exabyte_jobs_endpoint.get_compute(**job_config)\n",
    "\n",
    "        # Determine what we should name these jobs\n",
    "        job_prefix = f\"cu_slab_{miller_index}_Term{term}\"\n",
    "\n",
    "        # Get the material and workflow\n",
    "        material_id = surface[\"material_id\"]\n",
    "        workflow_id = workflow[\"_id\"]\n",
    "        material = exabyte_materials_endpoint.get(material_id)\n",
    "\n",
    "        # Set up the job and record the JOB ID, then submit the job\n",
    "        cu_slab_job = exabyte_jobs_endpoint.create_by_ids([material],\n",
    "                                                          workflow_id,\n",
    "                                                          project_id,\n",
    "                                                          ORGANIZATION_ID,\n",
    "                                                          job_prefix,\n",
    "                                                          compute)\n",
    "        surface[\"job_id\"] = cu_slab_job[0][\"_id\"]\n",
    "        exabyte_jobs_endpoint.submit(surface[\"job_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-skiing",
   "metadata": {},
   "source": [
    "# Extract Bulk and Slab Energy\n",
    "\n",
    "\n",
    "After our jobs complete, we can calculate the surface energy as follows:\n",
    "\n",
    "(E_Slab - E_bulk * (N_Slab / N_Bulk)) / (2A)\n",
    "\n",
    "We begin by extracting the total energy from the Cu unit cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dominant-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "cu_job_id = cu_job[0][\"_id\"]\n",
    "cu_bulk_energy = get_vasp_total_energy(cu_job_id, exabyte_jobs_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-accordance",
   "metadata": {},
   "source": [
    "Then, we extract the total energy from each of the slab runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "deluxe-science",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for miller_index, term_dict in cu_slabs.items():\n",
    "    for term, surface in term_dict.items():\n",
    "        surface[\"slab_energy\"] = get_vasp_total_energy(surface[\"job_id\"], exabyte_jobs_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-newton",
   "metadata": {},
   "source": [
    "# Calculate the Surface Energy\n",
    "We'll iterate over each slab and calculate the surface energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "textile-township",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 -28.83291559 -14.91181758 8 4 5.708565671242164\n",
      "332 -151.0572289 -14.91181758 42 4 30.917737832371877\n",
      "331 -75.54838808 -14.91181758 21 4 14.366241893582865\n",
      "110 -42.93178344 -14.91181758 12 4 9.322048705141237\n",
      "322 -129.30706145 -14.91181758 36 4 27.178208780541738\n",
      "321 -129.46770127 -14.91181758 36 4 24.663822583435387\n",
      "320 -107.14015568 -14.91181758 30 4 23.766654127088756\n",
      "311 -53.80104373 -14.91181758 15 4 10.931071040109009\n",
      "310 -107.74329863 -14.91181758 30 4 20.8447345942597\n",
      "100 -36.00421839 -14.91181758 10 4 6.591683853956643\n",
      "221 -100.695955 -14.91181758 28 4 19.77505156186993\n",
      "211 -86.41916363 -14.91181758 24 4 16.14626198793629\n",
      "210 -71.66973333 -14.91181758 20 4 14.739453183634847\n"
     ]
    }
   ],
   "source": [
    "for miller_index, term_dict in cu_slabs.items():\n",
    "    for term, surface in term_dict.items():\n",
    "        slab = surface[\"slab\"]\n",
    "        # Slab and bulk energy\n",
    "        e_slab = surface['slab_energy']\n",
    "        e_bulk = cu_bulk_energy\n",
    "\n",
    "        # N bulk and N Slab\n",
    "        cu_cell = ase.io.read(\"cu_relaxed.vasp\")\n",
    "        n_bulk = len(cu_cell)\n",
    "        n_slab = len(slab)\n",
    "\n",
    "        # Slab Area\n",
    "        vec_a = slab.cell[0]\n",
    "        vec_b = slab.cell[1]\n",
    "        area = get_slab_area(vec_a, vec_b)\n",
    "\n",
    "        print(miller_index, e_slab, e_bulk, n_slab, n_bulk, area)\n",
    "\n",
    "        # Surface Energy\n",
    "        surface_energy = get_surface_energy(e_slab=e_slab, e_bulk=e_bulk,\n",
    "                                            n_slab=n_slab, n_bulk=n_bulk,\n",
    "                                            a=area)\n",
    "        surface[\"surface_energy\"] = surface_energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-august",
   "metadata": {},
   "source": [
    "# Wulff Construction\n",
    "\n",
    "Finally, now that we have a collection of surfaces and their energies, we can perform the Wulff Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "stuffed-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaces = []\n",
    "energies = []\n",
    "for miller_index, term_dict in cu_slabs.items():\n",
    "    # Turn the string miller index into a list, for ASE\n",
    "    i,j,k = map(int, miller_index)\n",
    "    plane = (i,j,k)\n",
    "    surfaces.append(plane)\n",
    "    # Find the best termination for the surface\n",
    "    best_term_energy = np.inf\n",
    "    for term, surface in term_dict.items():\n",
    "        best_term_energy = min(best_term_energy, surface[\"surface_energy\"])\n",
    "    energies.append(best_term_energy)\n",
    "\n",
    "cluster_size = 147\n",
    "wulff = ase.cluster.wulff_construction(\"Cu\", surfaces=surfaces,\n",
    "                                       energies=energies, size=cluster_size,\n",
    "                                       structure = \"fcc\")\n",
    "\n",
    "ase.io.write(\"Cu_Wulff.xyz\", wulff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "listed-appraisal",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1) 0.087\n",
      "(3, 3, 2) 0.089\n",
      "(3, 2, 2) 0.09\n",
      "(2, 2, 1) 0.093\n",
      "(2, 1, 1) 0.095\n",
      "(3, 3, 1) 0.095\n",
      "(3, 2, 1) 0.096\n",
      "(1, 0, 0) 0.097\n",
      "(1, 1, 0) 0.097\n",
      "(3, 1, 1) 0.097\n",
      "(2, 1, 0) 0.098\n",
      "(3, 1, 0) 0.098\n",
      "(3, 2, 0) 0.099\n"
     ]
    }
   ],
   "source": [
    "for surf, en in sorted(zip(surfaces, energies), key = lambda i: i[1]):\n",
    "    print(surf, np.round(en,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-passage",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
